<!DOCTYPE html>
<html lang="zh-cn">
<head>
    <!--头部信息-->
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <!--title keywords description 请改为自己的-->
    <title>低调奋进</title>

    <!--网站favicon可以没有或者改为自己的-->
    <!--<link rel="shortcut icon" type="image/x-icon" href="http://www.bituplink.com/wp-content/uploads/favicon.png"/>-->

    <!--CSS 若不需要变动样式不用改-->
    <link href="plugin/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/zui/1.8.1/css/zui.min.css" rel="stylesheet" type="text/css"/>
    <link rel="stylesheet" type="text/css" href="../css/common.css" />
    <link href="../img/logo.ico" rel="shortcut icon" />
    <script src="plugin/jquery.min.js"></script>
    <script src="plugin/bootstrap/js/bootstrap.min.js"></script>
</head>
<body id="nav_body">
<!--[if lt IE 10]>
<div class="alert alert-danger">
    您正在使用 
    <strong>过时的</strong> 浏览器. 请更换一个更好的浏览器来提升用户体验.
</div>
<![endif]--><!--头部导航条-->
<div id="content">
    <div class="w_header">
      <div class="container">
        <div class="w_header_top">
          <a href="../index.html" class="w_logo"></a>
          <span class="w_header_nav">
              <ul>
                <li><a href="../index.html">Home</a></li>
                <li><a href="speech.html">Speech & ML</a></li>
                <li><a href="aigc.html" class="active">AIGC</a></li>
                <li><a href="https://yqlibook.readthedocs.io/en/latest/">yqliBook</a></li>
                <li><a href="pro.html">Programming</a></li>
                <li><a href="moodList.html">Life</a></li>
                <li><a href="tools.html">Tool</a></li>
                <li><a href="about.html">About</a></li>
            </ul>
        </span>
    </div>
</div>
</div>

<!--左侧Director，导航跳转-->
<div class="left-bar">
    <div class="header">
        <h2>Director</h2>
    </div>
    <div class="menu" id="menu">
        <ul class="scrollcontent">
            <!--左侧Director，按照需要修改和添加，参考已有的修改名称和href-->
            <li><a href="#row-1">Paper</a></li>
            <li><a href="#row-2">Code</a></li>
            <li><a href="#row-3">Dataset</a></li>
        </ul>
    </div>
</div>
<!--内容-->
<div class="main">
    <div class="container content-box">
        <h1>为中华民族崛起而奋斗！加油，少年！公众号：低调奋进</h1>
        <!--导航分类范例1，请根据自己的需求进行修改-->
        <section class="item card-box" id="row-1">
            <div class="container-fluid">
                <div class="row">
                    <div class="item-tit">
                        <strong>Paper</strong>
                    </div>
                    <div class="item-tit">
                        <strong>Survey</strong>
                    </div>
                        <table width="1100" border="1">                        
                            <tr>
                                <td width="100" align="center">1</td>
                                <td width="800">A Survey of Large Language Models</td>
                                <td width="200"><a href="https://arxiv.org/pdf/2303.18223.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">2</td>
                                <td width="800">Aligning Large Language Models with Human: A Survey</td>
                                <td width="200"><a href="https://arxiv.org/pdf/2307.12966.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">3</td>
                                <td width="800">A Comprehensive Overview of Large Language Models</td>
                                <td width="200"><a href="https://arxiv.org/pdf/2307.06435.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">4</td>
                                <td width="800">Large Language Models</td>
                                <td width="200"><a href="https://arxiv.org/pdf/2307.05782.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">5</td>
                                <td width="800">A Survey on Evaluation of Large Language Models</td>
                                <td width="200"><a href="https://arxiv.org/pdf/2307.03109.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">6</td>
                                <td width="800">Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning</td>
                                <td width="200"><a href="https://arxiv.org/pdf/2303.10475.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">7</td>
                                <td width="800">Challenges and Applications of Large Language Models</td>
                                <td width="200"><a href="https://arxiv.org/pdf/2307.10169.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">8</td>
                                <td width="800">A Survey on Model Compression for Large Language Models</td>
                                <td width="200"><a href="https://browse.arxiv.org/pdf/2308.07633.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">9</td>
                                <td width="800">How Can Recommender Systems Benefit from Large Language Models: A Survey</td>
                                <td width="200"><a href="https://browse.arxiv.org/pdf/2306.05817.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">10</td>
                                <td width="800">A Survey of Techniques for Optimizing Transformer Inference</td>
                                <td width="200"><a href="https://browse.arxiv.org/pdf/2307.07982.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">11</td>
                                <td width="800">Instruction Tuning for Large Language Models: A Survey</td>
                                <td width="200"><a href="https://browse.arxiv.org/pdf/2308.10792.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">12</td>
                                <td width="800">The Rise and Potential of Large Language Model Based Agents: A Survey</td>
                                <td width="200"><a href="https://browse.arxiv.org/pdf/2309.07864v1.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">13</td>
                                <td width="800">A Survey on Model Compression and Acceleration for Pretrained Language Models</td>
                                <td width="200"><a href="https://browse.arxiv.org/pdf/2202.07105.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">14</td>
                                <td width="800">Domain Specialization as the Key to Make Large Language Models Disruptive: A Comprehensive Survey</td>
                                <td width="200"><a href="https://browse.arxiv.org/pdf/2305.18703.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">15</td>
                                <td width="800">Explainability for Large Language Models: A Survey</td>
                                <td width="200"><a href="https://browse.arxiv.org/pdf/2309.01029.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">16</td>
                                <td width="800">The Rise and Potential of Large Language Model Based Agents: A Survey</td>
                                <td width="200"><a href="https://browse.arxiv.org/pdf/2309.07864.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">17</td>
                                <td width="800">TRUSTWORTHY LLMS: A SURVEY AND GUIDELINE FOR EVALUATING LARGE LANGUAGE MODELS’ ALIGNMENT</td>
                                <td width="200"><a href="https://browse.arxiv.org/pdf/2308.05374.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">18</td>
                                <td width="800">Large Language Model Alignment: A Survey</td>
                                <td width="200"><a href="https://browse.arxiv.org/pdf/2309.15025.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">19</td>
                                <td width="800">Bias and Fairness in Large Language Models: A Survey</td>
                                <td width="200"><a href="https://browse.arxiv.org/pdf/2309.00770.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">20</td>
                                <td width="800">A Survey on Fairness in Large Language Models</td>
                                <td width="200"><a href="https://browse.arxiv.org/pdf/2308.10149.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">21</td>
                                <td width="800">A Survey on Deep Neural Network Pruning: Taxonomy, Comparison, Analysis, and Recommendations</td>
                                <td width="200"><a href="https://browse.arxiv.org/pdf/2308.06767.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">22</td>
                                <td width="800">Towards Better Chain-of-Thought Prompting Strategies: A Survey</td>
                                <td width="200"><a href="https://arxiv.org/pdf/2310.04959.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">23</td>
                                <td width="800">A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics</td>
                                <td width="200"><a href="https://arxiv.org/pdf/2310.05694.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">24</td>
                                <td width="800">Augmenting LLMs with Knowledge: A survey on hallucination prevention</td>
                                <td width="200"><a href="https://arxiv.org/pdf/2309.16459.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">25</td>
                                <td width="800">From Instructions to Intrinsic Human Values -- A Survey of Alignment Goals for Big Models</td>
                                <td width="200"><a href="https://arxiv.org/pdf/2308.12014.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">26</td>
                                <td width="800">A Survey on Large Language Model based Autonomous Agents</td>
                                <td width="200"><a href="https://arxiv.org/pdf/2308.11432.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">27</td>
                                <td width="800">Through the Lens of Core Competency: Survey on Evaluation of Large Language Models</td>
                                <td width="200"><a href="https://arxiv.org/pdf/2308.07902.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">28</td>
                                <td width="800">Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback</td>
                                <td width="200"><a href="https://arxiv.org/pdf/2307.15217.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">29</td>
                                <td width="800">A Survey on Hallucination in Large Language Models</td>
                                <td width="200"><a href="https://arxiv.org/pdf/2309.01219.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">30</td>
                                <td width="800">Unifying Large Language Models and Knowledge Graphs: A Roadmap</td>
                                <td width="200"><a href="https://arxiv.org/pdf/2306.08302.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">31</td>
                                <td width="800">How Can Recommender Systems Benefit from Large Language Models: A Survey</td>
                                <td width="200"><a href="https://arxiv.org/abs/2306.05817">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">32</td>
                                <td width="800">Large Language Models for Information Retrieval: A Survey</td>
                                <td width="200"><a href="https://arxiv.org/abs/2308.07107">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">33</td>
                                <td width="800">Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity</td>
                                <td width="200"><a href="https://arxiv.org/pdf/2310.07521.pdf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">29</td>
                                <td width="800"></td>
                                <td width="200"><a href="">web</a></td>
                            </tr>
                        </table>
                    <div class="item-tit">
                        <strong>Paper</strong>
                    </div>
                    <!--获取内容列表-->

                    <table width="1100" border="1">
                        <tr>
                            <td width="100" align="center">1</td>
                            <td width="100">GPT 1</td>
                            <td width="700">Improving Language Understanding by Generative Pre-Training</td>
                            <td width="200"><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">2</td>
                            <td width="100">GPT 2</td>
                            <td width="700">Language Models are Unsupervised Multitask Learners</td>
                            <td width="200"><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">3</td>
                            <td width="100">GPT 3</td>
                            <td width="700">Language Models are Few-Shot Learners</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2005.14165.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">4</td>
                            <td width="100">Codex</td>
                            <td width="700">Evaluating Large Language Models Trained on Code</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2107.03374.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">5</td>
                            <td width="100">InstructGPT</td>
                            <td width="700">Training language models to follow instructions with human feedback</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2203.02155.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">6</td>
                            <td width="100">GPT 4</td>
                            <td width="700">GPT-4 Technical Report</td>
                            <td width="200"><a href="https://cdn.openai.com/papers/gpt-4.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">7</td>
                            <td width="100">GPT-4</td>
                            <td width="700">GPT-4 system card</td>
                            <td width="200"><a href="https://cdn.openai.com/papers/gpt-4-system-card.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">8</td>
                            <td width="100">prompt</td>
                            <td width="700">Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language ProcessingPre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing</td>
                            <td width="200"><a href="https://dl.acm.org/doi/pdf/10.1145/3560815">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">9</td>
                            <td width="100">RLHF</td>
                            <td width="700">Augmenting Reinforcement Learning with Human Feedback</td>
                            <td width="200"><a href=https://www.cs.utexas.edu/~ai-lab/pubs/ICML_IL11-knox.pdf"">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">10</td>
                            <td width="100">context</td>
                            <td width="700">What learning algorithm is in-context learning</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2211.15661.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">11</td>
                            <td width="100">ppo</td>
                            <td width="700">Proximal Policy Optimization Algorithms</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1707.06347.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">12</td>
                            <td width="100">TAMER</td>
                            <td width="700">Interactively Shaping Agents via Human Reinforcement</td>
                            <td width="200"><a href="https://www.cs.utexas.edu/~bradknox/papers/kcap09-knox.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">13</td>
                            <td width="100">GPT-4</td>
                            <td width="700">Sparks of Artificial General Intelligence Early experiments with GPT-4</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2303.12712.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">14</td>
                            <td width="100"></td>
                            <td width="700">Continual Pre-Training of Large Language Models: How to (re)warm your model?</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2308.04014.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">15</td>
                            <td width="100"></td>
                            <td width="700">Self-Alignment with Instruction Backtranslation</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2308.06259.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">16</td>
                            <td width="100"></td>
                            <td width="700">Llama 2: Open Foundation and Fine-Tuned Chat Models</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2307.09288.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">17</td>
                            <td width="100"></td>
                            <td width="700">The RefinedWeb Dataset for Falcon LLM</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2306.01116.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">18</td>
                            <td width="100"></td>
                            <td width="700">D4: Improving LLM Pretraining via Document De-Duplication and Diversification</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2308.12284.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">19</td>
                            <td width="100"></td>
                            <td width="700">Textbooks Are All You Need</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2306.11644.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">20</td>
                            <td width="100"></td>
                            <td width="700">How to Protect Copyright Data in Optimization of Large Language Models?</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2308.12247.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">21</td>
                            <td width="100"></td>
                            <td width="700">Baichuan 2: Open Large-scale Language Models</td>
                            <td width="200"><a href="https://cdn.baichuan-ai.com/paper/Baichuan2-technical-report.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">22</td>
                            <td width="100"></td>
                            <td width="700">LLaMA: Open and Efficient Foundation Language Models</td>
                            <td width="200"><a href="https://scontent-hkt1-2.xx.fbcdn.net/v/t39.8562-6/333078981_693988129081760_4712707815225756708_n.pdf?_nc_cat=108&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=F7hDQMmH8uIAX-5_VL-&_nc_ht=scontent-hkt1-2.xx&oh=00_AfCFhW0g1H7G0Pi0EchCFr8EephWi0GI0jSKRTP7e_pqdw&oe=652C65A2">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">23</td>
                            <td width="100"></td>
                            <td width="700">SlimPajama-DC: Understanding Data Combinations for LLM Training</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2309.10818.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">24</td>
                            <td width="100"></td>
                            <td width="700">Qwen technical report</td>
                            <td width="200"><a href="https://qianwen-res.oss-cn-beijing.aliyuncs.com/QWEN_TECHNICAL_REPORT.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">25</td>
                            <td width="100"></td>
                            <td width="700">LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale</td>
                            <td width="200"><a href="https://browse.arxiv.org/pdf/2208.07339.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">26</td>
                            <td width="100"></td>
                            <td width="700">GLM: General Language Model Pretraining with Autoregressive Blank Infilling</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2103.10360.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">27</td>
                            <td width="100"></td>
                            <td width="700">GLM-130B: AN OPEN BILINGUAL PRE-TRAINED MODEL</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2210.02414.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">28</td>
                            <td width="100"></td>
                            <td width="700">PaLM 2 Technical Report</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2305.10403.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">29</td>
                            <td width="100"></td>
                            <td width="700">OPT: Open Pre-trained Transformer Language Models</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2205.01068.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">30</td>
                            <td width="100"></td>
                            <td width="700">BLOOM: A 176B-Parameter Open-Access Multilingual Language Model</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2211.05100.pdf">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">31</td>
                            <td width="100"></td>
                            <td width="700"></td>
                            <td width="200"><a href="">web</a></td>
                        </tr>
                    </table>
                    <div class="item-tit">
                        <strong>Blog</strong>
                    </div>
                    <!--获取内容列表-->

                    <table width="1100" border="1">
                        <tr>
                            <td width="100" align="center">1</td>
                            <td width="800">关于ChatGPT的思考-李理 （强烈推荐)</td>
                            <td width="200"><a href="http://fancyerii.github.io/2023/02/20/about-chatgpt/#%E7%94%9F%E6%88%90%E6%96%87%E5%AD%97">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">2</td>
                            <td width="800">后GPT 3.0时代，主流大模型技术精要详解，走向AGI之路的大门已开</td>
                            <td width="200"><a href="https://www.51cto.com/article/744516.html">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">3</td>
                            <td width="800">拆解追溯 GPT-3.5 各项能力的起源</td>
                            <td width="200"><a href="https://yaofu.notion.site/GPT-3-5-360081d91ec245f29029d37b54573756">web</a></td>
                        <tr>
                            <td width="100" align="center">4</td>
                            <td width="800">Prompt 方法简介</td>
                            <td width="200"><a href="https://xiaosheng.run/2022/09/10/what-is-prompt.html">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">5</td>
                            <td width="800">吴恩达 prompt enginerring</td>
                            <td width="200"><a href="https://www.bilibili.com/video/BV1No4y1t7Zn/?spm_id_from=333.337.search-card.all.click">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">6</td>
                            <td width="800">大语言模型推理性能优化综述</td>
                            <td width="200"><a href="https://mp.weixin.qq.com/s/9mfx5ePcWYvWogeOMPTnqA">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">7</td>
                            <td width="800">万字综述：大语言模型驱动智能体(LLM Agent)进展与潜力 By 复旦+米哈游</td>
                            <td width="200"><a href="https://mp.weixin.qq.com/s/Or9MKs1C5kxti4vVNE51-g">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">8</td>
                            <td width="800">万字综述：大语言模型指令调优综述</td>
                            <td width="200"><a href="https://mp.weixin.qq.com/s/q56wkhhQVH0HhdXN6gTewQ">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">9</td>
                            <td width="800">一文了解大模型推理优化技术进展</td>
                            <td width="200"><a href="https://mp.weixin.qq.com/s/MB2QZTCYxRzO0OxHSdtFYw">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">10</td>
                            <td width="800">Do Machine Learning Models Memorize or Generalize?</td>
                            <td width="200"><a href="https://pair.withgoogle.com/explorables/grokking/">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">11</td>
                            <td width="800">An Initial Exploration of Theoretical Support for Language Model Data Engineering. Part 1: Pretraining </td>
                            <td width="200"><a href="https://yaofu.notion.site/An-Initial-Exploration-of-Theoretical-Support-for-Language-Model-Data-Engineering-Part-1-Pretraini-dc480d9bf7ff4659afd8c9fb738086eb">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">12</td>
                            <td width="800">符尧：别卷大模型训练了，来卷数据吧！</td>
                            <td width="200"><a href="https://mp.weixin.qq.com/s/jUjYnXO-7cXSEyAYbV9AqA">web</a></td>
                        </tr>
                    </table>
                    <div class="item-tit">
                        <strong>openai</strong>
                    </div>
                        <table width="1100" border="1">                        
                            <tr>
                                <td width="100" align="center">1</td>
                                <td width="100">openai</td>
                                <td width="700">openai</td>
                                <td width="200"><a href="https://openai.com">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">2</td>
                                <td width="100">openai chat</td>
                                <td width="700">chat</td>
                                <td width="200"><a href=https://chat.openai.com/chat"">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">3</td>
                                <td width="100">openai platform</td>
                                <td width="700">overview document examples playground</td>
                                <td width="200"><a href="https://platform.openai.com/docs/introduction">web</a></td>
                            </tr>
                        </table>
                    <div class="item-tit">
                        <strong>GPT tools</strong>
                    </div>
                    <table width="1100" border="1">
                        <tr>
                            <td width="100" align="center">1</td>
                            <td width="800">openai-cookbook</td>
                            <td width="200"><a href="https://github.com/openai/openai-cookbook">github</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">2</td>
                            <td width="800">Azure OpenAI</td>
                            <td width="200"><a href="https://github.com/Azure-Samples/azure-search-openai-demo">github</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">3</td>
                            <td width="800">go-openai</td>
                            <td width="200"><a href="https://github.com/sashabaranov/go-openai">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">4</td>
                            <td width="800">注册openai</td>
                            <td width="200"><a href="https://cloud.tencent.com/developer/article/2190154">web</a></td>
                        </tr>
                        <tr>
                            <td width="100" align="center">5</td>
                            <td width="800">ChatPaper</td>
                            <td width="200"><a href="https://github.com/kaixindelele/ChatPaper">github</a></td>
                        </tr>
                    </table>
                </div>
            </div>
        </section>
      	<section class="item card-box" id="row-2">
            <div class="container-fluid">
                <div class="row">
                    <div class="item-tit">
                        <strong>Code</strong>
                    </div>
                        <table width="1100" border="1">                        
                            <tr>
                                <td width="100" align="center">1</td>
                                <td width="300">DeepSpeed</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/microsoft/DeepSpeed">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">2</td>
                                <td width="300">Megatron-LM</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/NVIDIA/Megatron-LM">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">3</td>
                                <td width="300">transformers</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/huggingface/transformers">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">4</td>
                                <td width="300">Megatron-LLaMA</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/alibaba/Megatron-LLaMA">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">5</td>
                                <td width="300">Megatron-DeepSpeed</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/bigscience-workshop/Megatron-DeepSpeed">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">6</td>
                                <td width="300">ColossalAI</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/hpcaitech/ColossalAI">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">7</td>
                                <td width="300">BELLE</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/LianjiaTech/BELLE">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">8</td>
                                <td width="300">FastChat</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/lm-sys/FastChat">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">9</td>
                                <td width="300">langchain</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/langchain-ai/langchain">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">10</td>
                                <td width="300">llama</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/facebookresearch/llama">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">11</td>
                                <td width="300">llama.cpp</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/ggerganov/llama.cpp">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">12</td>
                                <td width="300">Chinese-LLaMA-Alpaca</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">13</td>
                                <td width="300">Llama2-Chinese</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/FlagAlpha/Llama2-Chinese">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">14</td>
                                <td width="300">TinyLlama</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/jzhang38/TinyLlama">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">15</td>
                                <td width="300">vllm</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/vllm-project/vllm">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">16</td>
                                <td width="300">Firefly</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/yangjianxin1/Firefly">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">17</td>
                                <td width="300">xformers</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/facebookresearch/xformers">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">18</td>
                                <td width="300">flash-attention</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/Dao-AILab/flash-attention">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">1</td>
                                <td width="300">streaming-llm</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/mit-han-lab/streaming-llm">web</a></td>
                            </tr>
                        </table>
                </div>
            </div>
        </section>
        <section class="item card-box" id="row-3">
            <div class="container-fluid">
                <div class="row">
                    <div class="item-tit">
                        <strong>Dataset</strong>
                    </div>
                    <div class="item-tit">
                        <strong>English</strong>
                   </div>
                        <table width="1100" border="1">                        
                            <tr>
                                <td width="100" align="center">1</td>
                                <td width="300">RedPajama</td>
                                <td width="500">1T tokens</td>
                                <td width="200"><a href="https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">2</td>
                                <td width="300">Pile</td>
                                <td width="500">825GiB</td>
                                <td width="200"><a href="https://huggingface.co/datasets/EleutherAI/pile">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">3</td>
                                <td width="300">SlimPajama</td>
                                <td width="500">627B</td>
                                <td width="200"><a href="https://huggingface.co/datasets/cerebras/SlimPajama-627B">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">4</td>
                                <td width="300">falcon-refinedweb </td>
                                <td width="500">1.68TB</td>
                                <td width="200"><a href="https://huggingface.co/datasets/tiiuae/falcon-refinedweb">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">5</td>
                                <td width="300">BigScience Data</td>
                                <td width="500">300B</td>
                                <td width="200"><a href="https://huggingface.co/bigscience-data">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">6</td>
                                <td width="300">oscar</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://huggingface.co/oscar-corpus">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">7</td>
                                <td width="300">openwebtext</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://huggingface.co/datasets/Skylion007/openwebtext">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">7</td>
                                <td width="300">C4</td>
                                <td width="500">305G</td>
                                <td width="200"><a href="https://huggingface.co/datasets/c4">web</a></td>
                            </tr>
                        </table>
                <div class="item-tit">
                        <strong>Code & Math</strong>
                </div>
                        <table width="1100" border="1">                        
                            <tr>
                                <td width="100" align="center">1</td>
                                <td width="300">starcoderdata</td>
                                <td width="500">250B tokens</td>
                                <td width="200"><a href="https://huggingface.co/datasets/bigcode/starcoderdata">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">2</td>
                                <td width="300">MathGLM</td>
                                <td width="500">3G</td>
                                <td width="200"><a href="https://cloud.tsinghua.edu.cn/d/8d9ee3e52bb54afd9c16/">web</a></td>
                            </tr>
                        </table>
                    <div class="item-tit">
                        <strong>Chinese</strong>
                    </div>
                        <table width="1100" border="1">                        
                            <tr>
                                <td width="100" align="center">1</td>
                                <td width="300">MNBVC</td>
                                <td width="500">目标40T,一直进行中</td>
                                <td width="200"><a href="https://github.com/esbatmop/MNBVC">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">2</td>
                                <td width="300">CLUECorpus2020</td>
                                <td width="500">100G高质量语料</td>
                                <td width="200"><a href="https://github.com/CLUEbenchmark/CLUECorpus2020">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">3</td>
                                <td width="300">xuanyuan</td>
                                <td width="500">开源60G，在更新</td>
                                <td width="200"><a href="https://github.com/Duxiaoman-DI/XuanYuan">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">4</td>
                                <td width="300">wudao</td>
                                <td width="500">开源200G</td>
                                <td width="200"><a href="https://data.baai.ac.cn/details/WuDaoCorporaText">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">5</td>
                                <td width="300">TigerBot</td>
                                <td width="500">开源100G,英文51G,中文55G</td>
                                <td width="200"><a href="https://huggingface.co/datasets/TigerResearch/pretrain_zh">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">6</td>
                                <td width="300">llm-dataset-chinese-poetry</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/CanvaChen/llm-dataset-chinese-poetry">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">7</td>
                                <td width="300">CC-100</td>
                                <td width="500">多语言中中文54G</td>
                                <td width="200"><a href="https://data.statmt.org/cc-100/">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">8</td>
                                <td width="300">源1.0</td>
                                <td width="500">开源1T需要申请</td>
                                <td width="200"><a href="https://aijishu.com/a/1060000000299342">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">9</td>
                                <td width="300">CBook-150k</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/FudanNLPLAB/CBook-150K">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">10</td>
                                <td width="300">awesome-chinese-legal-resources</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/pengxiao-song/awesome-chinese-legal-resources">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">11</td>
                                <td width="300">chinese-poetry</td>
                                <td width="500"></td>
                                <td width="200"><a href=" https://github.com/chinese-poetry/chinese-poetry">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">12</td>
                                <td width="300">commoncrawl/</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://commoncrawl.org/">web</a></td>
                            </tr>
                        </table>
                <div class="item-tit">
                        <strong>Alignment(sft & rlhf)</strong>
                </div>
                        <table width="1100" border="1">                        
                            <tr>
                                <td width="100" align="center">1</td>
                                <td width="300">COIG</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://huggingface.co/BAAI">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">2</td>
                                <td width="300">ShareGPT-Chinese-English-90k </td>
                                <td width="500"></td>
                                <td width="200"><a href="https://huggingface.co/datasets/shareAI/ShareGPT-Chinese-English-90k">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">3</td>
                                <td width="300">ShareGPT52K</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://huggingface.co/datasets/RyokoAI/ShareGPT52K">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">4</td>
                                <td width="300">belle</td>
                                <td width="500">3.5M_CN</td>
                                <td width="200"><a href="https://huggingface.co/datasets/BelleGroup/train_3.5M_CN">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">5</td>
                                <td width="300">databricks-dolly-15k </td>
                                <td width="500"></td>
                                <td width="200"><a href="https://huggingface.co/datasets/databricks/databricks-dolly-15k">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">6</td>
                                <td width="300">alpaca-gpt4</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://huggingface.co/datasets/vicgalle/alpaca-gpt4">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">7</td>
                                <td width="300">GPT-4-LLM</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/blob/main/data/alpaca_gpt4_data.json">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">8</td>
                                <td width="300">Cot</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://huggingface.co/datasets/QingyiSi/Alpaca-CoT/tree/main">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">9</td>
                                <td width="300">InstructionWild</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/XueFuzhao/InstructionWild">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">10</td>
                                <td width="300">GuanacoDataset</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://huggingface.co/datasets/JosephusCheung/GuanacoDataset">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">11</td>
                                <td width="300">Huatuo-Llama-Med-Chinese</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">12</td>
                                <td width="300">OpenOrca </td>
                                <td width="500"></td>
                                <td width="200"><a href="https://huggingface.co/datasets/Open-Orca/OpenOrca">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">13</td>
                                <td width="300">LongForm</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://github.com/akoksal/LongForm">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">14</td>
                                <td width="300">code_instructions_120k_alpaca </td>
                                <td width="500"></td>
                                <td width="200"><a href="https://huggingface.co/datasets/iamtarun/code_instructions_120k_alpaca">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">15</td>
                                <td width="300">lima</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://huggingface.co/datasets/GAIR/lima">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">16</td>
                                <td width="300">wizard_vicuna_70k</td>
                                <td width="500"></td>
                                <td width="200"><a href="https://huggingface.co/datasets/junelee/wizard_vicuna_70k">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">17</td>
                                <td width="300">wizard_vicuna_70k_unfiltered </td>
                                <td width="500"></td>
                                <td width="200"><a href="https://huggingface.co/datasets/ehartford/wizard_vicuna_70k_unfiltered">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">18</td>
                                <td width="300">hh-rlhf </td>
                                <td width="500"></td>
                                <td width="200"><a href="https://huggingface.co/datasets/Anthropic/hh-rlhf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">19</td>
                                <td width="300">full-hh-rlhf </td>
                                <td width="500"></td>
                                <td width="200"><a href="https://huggingface.co/datasets/Dahoas/full-hh-rlhf">web</a></td>
                            </tr>
                            <tr>
                                <td width="100" align="center">1</td>
                                <td width="300"></td>
                                <td width="500"></td>
                                <td width="200"><a href="">web</a></td>
                            </tr>
                        </table>
              
                </div>
            </div>
        </section>
       
<footer class="footer">
    <div class="container">
        <div class="rwo">
            <div class="col-md-12">
                <p>
                    本站内容源自互联网，如有内容侵犯了你的权益，请联系删除相关内容，联系邮箱：yongqiangli@alumni.hust.edu.cn
                </p>
                <!--代码源自小呆导航的开源代码，遵循MIT协议，此处保留源代码的声明-->
                <p>
                    Copyright © 2015-2035 li yongqiang All Rights Reserved
                </p>
            </div>
        </div>
    </div>
</footer>
</div>
<!--内容区域-->
</div>
<div id="get-top" title="回到顶部">
    <i class="icon icon-arrow-up"></i>
</div>

<!-- jQuery (ZUI中的Javascript组件依赖于jQuery) -->
<script src="http://code.jquery.com/jquery-1.11.0.min.js"></script>

<script>
    window.onscroll = function(){
//回到顶部
var sllTop = document.documentElement.scrollTop||document.body.scrollTop;
if(sllTop>240){
  $('#get-top').css('display','block')
}else{
  $('#get-top').css('display','none')
}
}
$('#get-top').click(function(){ 
  $('body,html').animate({
    scrollTop: 0
  }, 800);//点击回到顶部按钮，数字越小越快
})
//判断用户使用的设备
var deviceVal  = browserRedirect();
function browserRedirect() {
  var sUserAgent = navigator.userAgent.toLowerCase();
  var bIsIpad = sUserAgent.match(/ipad/i) == "ipad";
  var bIsIphoneOs = sUserAgent.match(/iphone os/i) == "iphone os";
  var bIsMidp = sUserAgent.match(/midp/i) == "midp";
  var bIsUc7 = sUserAgent.match(/rv:1.2.3.4/i) == "rv:1.2.3.4";
  var bIsUc = sUserAgent.match(/ucweb/i) == "ucweb";
  var bIsAndroid = sUserAgent.match(/android/i) == "android";
  var bIsCE = sUserAgent.match(/windows ce/i) == "windows ce";
  var bIsWM = sUserAgent.match(/windows mobile/i) == "windows mobile";
  if (bIsIpad || bIsIphoneOs || bIsMidp || bIsUc7 || bIsUc || bIsAndroid || bIsCE || bIsWM) {
    return 'phone';
} else {
    return 'pc';
}
}
$('.nav-btn').on('click', function () {
    $('.nav').toggleClass('showNav');
    $(this).toggleClass('animated2');
});

// 默认搜索引擎的内容，如果界面修改了需要同步修改
var thisSearch = 'http://www.caup.cn/search?q=';

$('#txt').keydown(function(ev){
    // 回车键的处理
    if(ev.keyCode==13){
        window.open(thisSearch + $('#txt').val())
        // $('#txt').val('');
        $('#box ul').html('')
    }
})
$(function(){
  // 搜索引擎列表，样式一行五个内容，自动换行
  var search = {
    data: [{
      name: '小众搜索',
      url: 'http://www.caup.cn/search?q='
  }, {
      name: '百度',
      url: 'https://www.baidu.com/s?wd='
  }, {
      name: '谷歌',
      url: 'https://www.google.com/search?q='
  }, {
      name: '必应',
      url: 'https://cn.bing.com/search?q='
  }, {
      name: '好搜',
      url: 'https://www.so.com/s?q='
  }, {
      name: '搜狗',
      url: 'https://www.sogou.com/web?query='
  }, {
      name: '淘宝',
      url: 'https://s.taobao.com/search?q='
  }, {
      name: '京东',
      url: 'http://search.jd.com/Search?keyword='
  }, {
      name: '天猫',
      url: 'https://list.tmall.com/search_product.htm?q='
  }, {
      name: '1688',
      url: 'https://s.1688.com/selloffer/offer_search.htm?keywords='
  }, {
      name: '知乎',
      url: 'https://www.zhihu.com/search?type=content&q='
  }, {
      name: '微博',
      url: 'https://s.weibo.com/weibo/'
  }, {
      name: 'Bilibili',
      url: 'http://search.bilibili.com/all?keyword='
  }, {
      name: '豆瓣',
      url: 'https://www.douban.com/search?source=suggest&q='
  }, {
      name: '优酷',
      url: 'https://so.youku.com/search_video/q_'
  }, {
      name: 'GitHub',
      url: 'https://github.com/search?q='
  }]
}
for(var i = 0; i < search.data.length; i++){
    var addList = '<li>' + search.data[i].name + '</li>'
    $('.search-engine-list').append(addList);
}
$('.search-engine-name, .search-engine').hover(function() {
    $('.search-engine').css('display', 'block')
}, function() {
    $('.search-engine').css('display', 'none')
});
$('.search-engine-list li').click(function() {
    var _index = $(this).index();
    var searchNameBtn = document.getElementById("search-engine-name");
    searchNameBtn.innerHTML = search.data[_index].name;
    thisSearch = search.data[_index].url;
    $('.search-engine').css('display', 'none')
})
})
$("#search-btn").click(function(){
  var textValue = $('#txt').val();
  if(textValue != ''){
    window.open(thisSearch + textValue)
}
});
</script>
</div>
</body>
</html>
