<!DOCTYPE html>
<html lang="zh-cn">
<head>
    <!--头部信息-->
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <!--title keywords description 请改为自己的-->
    <title>低调奋进</title>

    <!--网站favicon可以没有或者改为自己的-->
    <!--<link rel="shortcut icon" type="image/x-icon" href="http://www.bituplink.com/wp-content/uploads/favicon.png"/>-->

    <!--CSS 若不需要变动样式不用改-->
    <link href="plugin/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/zui/1.8.1/css/zui.min.css" rel="stylesheet" type="text/css"/>
    <link rel="stylesheet" type="text/css" href="../css/common.css" />
    <link href="../img/logo.ico" rel="shortcut icon" />
    <script src="plugin/jquery.min.js"></script>
    <script src="plugin/bootstrap/js/bootstrap.min.js"></script>
</head>
<body id="nav_body">
<!--[if lt IE 10]>
<div class="alert alert-danger">
    您正在使用 
    <strong>过时的</strong> 浏览器. 请更换一个更好的浏览器来提升用户体验.
</div>
<![endif]--><!--头部导航条-->
<div id="content">
    <div class="w_header">
      <div class="container">
        <div class="w_header_top">
          <a href="../index.html" class="w_logo"></a>
          <span class="w_header_nav">
              <ul>
                <li><a href="../index.html">Home</a></li>
                <li><a href="speech.html" class="active">Speech & ML</a></li>
                <li><a href="pro.html">Programming</a></li>
                <li><a href="moodList.html">Life</a></li>
                <li><a href="tools.html">Tool</a></li>
                <li><a href="about.html">About</a></li>
            </ul>
        </span>
    </div>
</div>
</div>

<!--左侧Director，导航跳转-->
<div class="left-bar">
    <div class="header">
        <h2>Director</h2>
    </div>
    <div class="menu" id="menu">
        <ul class="scrollcontent">
            <!--左侧Director，按照需要修改和添加，参考已有的修改名称和href-->
            <li><a href="#row-1">Hybrid ASR & General</a></li>
            <li><a href="#row-2">RNN-T</a></li>
            <li><a href="#row-3">CTC</a></li>
            <li><a href="#row-4">AED</a></li>
            <li><a href="#row-5">Unified & Rescoring</a></li>
            <li><a href="#row-6">Data Aug</a></li>
            <li><a href="#row-7">LM</a></li>
            <li><a href="#row-8">Unsupervised</a></li>
            <li><a href="#row-9">Multilingual</a></li>
            <li><a href="#row-10">Personal</a></li>
            <li><a href="#row-11">Accent</a></li>
            <li><a href="#row-12">Dataset</a></li>
            <li><a href="#row-13">Robust</a></li>
            <li><a href="#row-14">Speaker Diarization</a></li>
            <li><a href="#row-15">MultiChannel</a></li>
            <li><a href="#row-16">MultiModal</a></li>
            <li><a href="#row-17">Speech Translation</a></li>
            <li><a href="#row-18">Other</a></li>
        </ul>
    </div>
</div>
<!--内容-->
<div class="main">
    <div class="container content-box">
        <!--导航分类范例1，请根据自己的需求进行修改-->
        <section class="item card-box" id="row-1">
            <div class="container-fluid">
                <div class="row">
                    <div class="item-tit">
                        <strong>Journal and conference on speech</strong>
                        <table width="1150" border="1">
                            <tr>
                                <td width="150" align="center">CCF-A</a></td>
                                <td width="1000">NeuraIPS&nbsp;&nbsp;&nbsp;AAAI&nbsp;&nbsp;&nbsp;IJAI&nbsp;&nbsp;&nbsp;ACMMM </td>
                            </tr>
                            <tr>
                                <td width="150" align="center">CCF-B</a></td>
                                <td width="1000">ICASSP&nbsp;&nbsp;&nbsp;COLING&nbsp;&nbsp;&nbsp;SpeechCom&nbsp;&nbsp;&nbsp;TSLP&nbsp;&nbsp;&nbsp;TASLP&nbsp;&nbsp;&nbsp;JSLHR&nbsp;&nbsp;&nbsp;TMM&nbsp;&nbsp;&nbsp;TOMCCAP&nbsp;&nbsp;&nbsp;ICME </td>
                            </tr>
                            <tr>
                                <td width="150" align="center">CCF-C</a></td>
                                <td width="1000">INTERSPEECH&nbsp;&nbsp;&nbsp;ICPR </td>
                            </tr>
                            <tr>
                                <td width="150" align="center">other</a></td>
                                <td width="1000">ICLR </td>
                            </tr>
                        </table>
                    </div>
                    <div class="item-tit">
                        <strong>Hybrid & General ASR</strong>
                    </div>
                    <!--获取内容列表-->
            <h3> 2022 </h3>
            <table width="1150" border="1">
                <tr>
                    <td width="150" align="center">1</a></td>
                    <td width="800">Improving End-to-End Contextual Speech Recognition with Fine-grained Contextual Knowledge Selection</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.12806.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">2</a></td>
                    <td width="800">Sentiment-Aware Automatic Speech Recognition pre-training for enhanced Speech Emotion Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.11826.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">3</a></td>
                    <td width="800">Internal language model estimation through explicit context vector learning for attention-based encoder-decoder ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.11627.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">4</a></td>
                    <td width="800">Synthesizing Dysarthric Speech Using Multi-talker TTS for Dysarthric Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.11571.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">5</a></td>
                    <td width="800">Dual-Decoder Transformer For end-to-end Mandarin Chinese Speech Recognition with Pinyin and Character</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.10792.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">6</a></td>
                    <td width="800">Transformer-Based Video Front-Ends for Audio-Visual Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.10439.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">7</a></td>
                    <td width="800">Human and Automatic Speech Recognition Performance on German Oral History Interviews</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.06841.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">8</a></td>
                    <td width="800">Recent Progress in the CUHK Dysarthric Speech Recognition System</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.05845.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">9</a></td>
                    <td width="800">The Effectiveness of Time Stretching for Enhancing Dysarthric Speech for Improved Dysarthric Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.04908.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">10</a></td>
                    <td width="800">Run-and-back stitch search: novel block synchronous decoding for streaming encoder-decoder ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.10190.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">11</a></td>
                    <td width="800">Ask2Mask: Guided Data Selection for Masked Speech Modeling</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.12719.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">12</a></td>
                    <td width="800">The PCG-AIID System for L3DAS22 Challenge: MIMO and MISO convolutional recurrent Network for Multi Channel Speech Enhancement and Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.10017.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">13</a></td>
                    <td width="800">Non-Autoregressive ASR with Self-Conditioned Folded Encoders</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.08474.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">14</a></td>
                    <td width="800">MLP-ASR: Sequence-length agnostic all-MLP architectures for speech recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.08456.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">15</a></td>
                    <td width="800">Conversational Speech Recognition By Learning Conversation-level Characteristics</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.07855.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">16</a></td>
                    <td width="800">The RoyalFlush System of Speech Recognition for M2MeT Challenge</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.01614.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">17</a></td>
                    <td width="800">Visual Speech Recognition for Multiple Languages in the Wild</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.13084.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">18</a></td>
                    <td width="800">Spanish and English Phoneme Recognition by Training on Simulated Classroom Audio Recordings of Collaborative Learning Environments</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.10536.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">19</a></td>
                    <td width="800">Wav2Vec2.0 on the Edge: Performance Evaluation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.05993.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">20</a></td>
                    <td width="800">4-bit Conformer with Native Quantization Aware Training for Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.15952.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">21</a></td>
                    <td width="800">A Comparative Study on Speaker-attributed Automatic Speech Recognition in Multi-party Meetings</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16834.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">22</a></td>
                    <td width="800">Chain-based Discriminative Autoencoders for Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.13687.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">23</a></td>
                    <td width="800">CUSIDE: Chunking, Simulating Future Context and Decoding for Streaming ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16758.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">24</a></td>
                    <td width="800">Enhancing Speech Recognition Decoding via Layer Aggregation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.11325.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">25</a></td>
                    <td width="800">Extended Graph Temporal Classification for Multi-Speaker End-to-End ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.00232.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">26</a></td>
                    <td width="800">Locality Matters: A Locality-Biased Linear Attention for Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.15609.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">27</a></td>
                    <td width="800">Shifted Chunk Encoder for Transformer Based Streaming End-to-End ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.15206.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">28</a></td>
                    <td width="800">Similarity and Content-based Phonetic Self Attention for Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.10252.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">29</a></td>
                    <td width="800">Speaker recognition by means of a combination of linear and nonlinear predictive models</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.03190.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">30</a></td>
                    <td width="800">STEMM: Self-learning with Speech-text Manifold Mixup for Speech Translation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.10426.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">31</a></td>
                    <td width="800">Streaming Speaker-Attributed ASR with Token-Level Speaker Embeddings</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16685.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">32</a></td>
                    <td width="800">Transformer-based Streaming ASR with Cumulative Attention</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.05736.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">33</a></td>
                    <td width="800">Improving non-autoregressive end-to-end speech recognition with pre-trained acoustic and language models</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.10103.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">34</a></td>
                    <td width="800">Variational Auto-Encoder Based Variability Encoding for Dysarthric Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.09422.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">35</a></td>
                    <td width="800">Improved far-field speech recognition using Joint Variational Autoencoder</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.11286.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">36</a></td>
                    <td width="800">E2E Segmenter: Joint Segmenting and Decoding for Long-Form ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.10749.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">37</a></td>
                    <td width="800">Self-critical Sequence Training for Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.06260.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">38</a></td>
                    <td width="800">3M: Multi-loss, Multi-path and Multi-level Neural Networks for speech recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.03178.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">39</a></td>
                    <td width="800">A Complementary Joint Training Approach Using Unpaired Speech and Text for Low-Resource Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.02023.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">40</a></td>
                    <td width="800">Text-To-Speech Data Augmentation for Low Resource Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.00291.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">41</a></td>
                    <td width="800">Multiple Confidence Gates For Joint Training Of SE And ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.00226.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">42</a></td>
                    <td width="800">End-to-End Multi-speaker ASR with Independent Vector Analysis</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.00218.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">43</a></td>
                    <td width="800">Filter-based Discriminative Autoencoders for Children Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.00164.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">44</a></td>
                    <td width="800">Global Normalization for Streaming Speech Recognition in a Modular Framework</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.13674.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">45</a></td>
                    <td width="800">Heterogeneous Reservoir Computing Models for Persian Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.12594.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">46</a></td>
                    <td width="800">PaddleSpeech: An Easy-to-Use All-in-One Speech Toolkit</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.12007.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">47</a></td>
                    <td width="800">Multi-Level Modeling Units for End-to-End Mandarin Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.11998.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">48</a></td>
                    <td width="800">Minimising Biasing Word Errors for Contextual ASR with the Tree-Constrained Pointer Generator</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.09058.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">49</a></td>
                    <td width="800">Unified Modeling of Multi-Domain Multi-Device ASR Systems</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.06655.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">50</a></td>
                    <td width="800">Conformer with dual-mode chunked attention for joint online and offline ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.11157.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">51</a></td>
                    <td width="800">Context-based out-of-vocabulary word recovery for ASR systems in Indian languages</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.04305.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">52</a></td>
                    <td width="800">Improving the Training Recipe for a Robust Conformer-based Hybrid Model</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.12955.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">53</a></td>
                    <td width="800">Nextformer: A ConvNeXt Augmented Conformer For End-To-End Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.14747.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">54</a></td>
                    <td width="800">Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.08317.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">55</a></td>
                    <td width="800">Squeezeformer: An Efficient Transformer for Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.00888.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">56</a></td>
                    <td width="800">Supervision-Guided Codebooks for Masked Prediction in Speech Pre-training</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.10125.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">57</a></td>
                    <td width="800">Learning a Dual-Mode Speech Recognition Model via Self-Pruning</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.11906.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">58</a></td>
                    <td width="800">Improving Mandarin Speech Recogntion with Block-augmented Transformer</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.11697.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">59</a></td>
                    <td width="800">Toward Fairness in Speech Recognition: Discovery and mitigation of performance disparities</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.11345.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">60</a></td>
                    <td width="800">Online Continual Learning of End-to-End Speech Recognition Models</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.05071.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">61</a></td>
                    <td width="800">Intermediate-layer output Regularization for Attention-based Speech Recognition with Shared Decoder</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.04177.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">62</a></td>
                    <td width="800">Improving Streaming End-to-End ASR on Transformer-based Causal Models with Encoder States Revision Strategies</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.02495.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">63</a></td>
                    <td width="800">Compute Cost Amortized Transformer for Streaming ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.02393.pdf">pdf</a></td>
                </tr>
            </table>
                    <h3> 2021 </h3>
                    <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">The History of Speech Recognition to the Year 2030</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2108.00084.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Multilingual Speech Recognition using Knowledge Transfer across Learning Processes</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.07909.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Efficient domain adaptation of language models in ASR systems using Prompt-tuning</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.06502.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">Word Order Does Not Matter For Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.05994.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">Internal Language Model Adaptation with Text-Only Data for End-to-End Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.05354.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">Interactive Feature Fusion for End-to-End Noise-Robust Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.05267.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</a></td>
                            <td width="800">Personalized Automatic Speech Recognition Trained on Small Disordered Speech Datasets</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.04612.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">8</a></td>
                            <td width="800">A Study of Low-Resource Speech Commands Recognition based on Adversarial Reprogramming</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.03894.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">9</a></td>
                            <td width="800">AequeVox: Automated Fairness Testing of Speech Recognition Systems</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.09843.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">10</a></td>
                            <td width="800">An Exploration of Self-Supervised Pretrained Representations for End-to-End Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.04590.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">11</a></td>
                            <td width="800">synchronous Decentralized Distributed Training of Acoustic Models</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.11199.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">12</a></td>
                            <td width="800">Beyond Lp clipping: Equalization-based Psychoacoustic Attacks against ASRs</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.13250.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">13</a></td>
                            <td width="800">Continual learning using lattice-free MMI for speech recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.07055.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">14</a></td>
                            <td width="800">Explaining the Attention Mechanism of End-to-End Speech Recognition Using Decision Trees</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.03879.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">15</a></td>
                            <td width="800">Exploring Heterogeneous Characteristics of Layers in ASR Models for More Efficient Training</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.04267.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">16</a></td>
                            <td width="800">FastCorrect 2: Fast Error Correction on Multiple Candidates for Automatic Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2109.14420.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">17</a></td>
                            <td width="800">improving Character Error Rate Is Not Equal to Having Clean Speech: Speech Enhancement for ASR Systems with Black-box Acoustic Model</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.05968.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">18</a></td>
                            <td width="800">Improving Confidence Estimation on Out-of-Domain Data for End-to-End Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.03327.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">19</a></td>
                            <td width="800">Improving Pseudo-label Training For End-to-end Speech Recognition Using Gradient Mask</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.04056.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">20</a></td>
                            <td width="800">Integrating Categorical Features in End-to-End ASR</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.03047.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">21</a></td>
                            <td width="800">Interactive Feature Fusion for End-to-End Noise-Robust Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.05267.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">22</a></td>
                            <td width="800">Multi-Modal Pre-Training for Automated Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.09890.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">23</a></td>
                            <td width="800">Omni-sparsity DNN: Fast Sparsity Optimization for On-Device Streaming E2E ASR via Supernet</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.08352.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">24</a></td>
                            <td width="800">Optimizing Alignment of Speech and Language Latent Spaces for End-to-End Speech Recognition and Understanding</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.12138.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">25</a></td>
                            <td width="800">Parallel Composition of Weighted Finite-State Transducers</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.02848.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">26</a></td>
                            <td width="800">SCaLa: Supervised Contrastive Learning for End-to-End Automatic Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.04187.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">27</a></td>
                            <td width="800">Speech Pattern based Black-box Model Watermarking for Automatic Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.09814.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">28</a></td>
                            <td width="800">Speech Technology for Everyone: Automatic Speech Recognition for Non-Native English with Transfer Learning</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.00678.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">29</a></td>
                            <td width="800">Spell my name: keyword boosted speech recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.02791.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">30</a></td>
                            <td width="800">Towards efficient end-to-end speech recognition with biologically-inspired neural networks</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.02743.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">31</a></td>
                            <td width="800">Transcribe-to-Diarize: Neural Speaker Diarization for Unlimited Number of Speakers using End-to-End Speaker-Attributed ASR</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.03151.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">32</a></td>
                            <td width="800">Wav2vec-Switch: Contrastive Learning from Original-noisy Speech Pairs for Robust Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.04934.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">33</a></td>
                            <td width="800">Word Order Does Not Matter For Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.05994.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">34</a></td>
                            <td width="800">Voice Conversion Can Improve ASR in Very Low-Resource Settings</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.02674.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">35</a></td>
                            <td width="800">Towards Building ASR Systems for the Next Billion Users</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.03945.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">36</a></td>
                            <td width="800">Scaling ASR Improves Zero and Few Shot Learning</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.05948.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">37</a></td>
                            <td width="800">Romanian Speech Recognition Experiments from the ROBIN Project</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.12028.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">38</a></td>
                            <td width="800">Retrieving Speaker Information from Personalized Acoustic Models for Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.04194.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">39</a></td>
                            <td width="800">Recent Advances in End-to-End Automatic Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.01690.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">40</a></td>
                            <td width="800">Privacy attacks for automatic speech recognition acoustic models in a federated learning framework</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.03777.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">41</a></td>
                            <td width="800">Multi-Channel Multi-Speaker ASR Using 3D Spatial Feature</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.11023.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">42</a></td>
                            <td width="800">Mixed Precision DNN Qunatization for Overlapped Speech Separation and Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.14479.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">43</a></td>
                            <td width="800">Integrated Semantic and Phonetic Post-correction for Chinese Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.08400.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">44</a></td>
                            <td width="800">Effect of noise suppression losses on speech distortion and ASR performance</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.11606.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">45</a></td>
                            <td width="800">Do We Still Need Automatic Speech Recognition for Spoken Language Understanding?</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.14842.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">46</a></td>
                            <td width="800">Conformer-based Hybrid ASR System for Switchboard Dataset</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.03442.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">47</a></td>
                            <td width="800">A comparison of streaming models and data augmentation methods for robust speech recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.10043.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">48</a></td>
                            <td width="800">Are E2E ASR models ready for an industrial usage?</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.12572.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">49</a></td>
                            <td width="800">Voice Quality and Pitch Features in Transformer-Based Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.11391.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">50</a></td>
                            <td width="800">Investigation of Densely Connected Convolutional Networks with Domain Adversarial Learning for Noise Robust Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.10108.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">51</a></td>
                            <td width="800">Continual Learning for Monolingual End-to-End Automatic Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.09427.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">52</a></td>
                            <td width="800">Domain Prompts: Towards memory and compute efficient domain adaptation of ASR systems</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.08718.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">53</a></td>
                            <td width="800">Speech frame implementation for speech analysis and recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.08027.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">54</a></td>
                            <td width="800">Improving Speech Recognition on Noisy Speech via Speech Enhancement with Multi-Discriminators CycleGAN</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.06309.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">55</a></td>
                            <td width="800">Directed Speech Separation for Automatic Speech Recognition of Long Form Conversational Speech</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.05863.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">56</a></td>
                            <td width="800">Revisiting the Boundary between ASR and NLU in the Age of Conversational Dialog Systems</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.05842.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">57</a></td>
                            <td width="800">Training end-to-end speech-to-text models on mobile phones</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.03871.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">58</a></td>
                            <td width="800">Robust Speech Representation Learning via Flow-based Embedding Regularization</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.03454.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">59</a></td>
                            <td width="800">A Mixture of Expert Based Deep Neural Network for Improved ASR</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.01025.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">60</a></td>
                            <td width="800">A higher order Minkowski loss for improved prediction ability of acoustic model in ASR</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.01023.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">61</a></td>
                            <td width="800">X-Vector based voice activity detection for multi-genre broadcast speech-to-text</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.05016.pdf">pdf</a></td>
                        </tr>
                     </table>
            <h3> 2020 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">On the Comparison of Popular End-to-End Models for Large Scale Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2005.14327.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Conformer: Convolution-augmented Transformer for Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2005.08100v1.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2005.03191.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">Improved Noisy Student Training for Automatic Speech Recognition(</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2005.09629.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">CIF: Continuous Integrate-And-Fire for End-To-End Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1905.11235.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">A Comparison of Label-Synchronous and Frame-Synchronous End-to-End Models for Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2005.10113.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</a></td>
                            <td width="800">Imputer: Sequence modelling via imputation and dynamic programming</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2002.08926.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">8</a></td>
                            <td width="800">Automatic Speech Recognition Errors Detection and Correction: A Review</td>
                            <td width="200"><a href="http://icnlsp.org/IMG/pdf/-12.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">9</a></td>
                            <td width="800">A review of on-device fully neural end-to-end automatic speech recognition algorithms </td>
                            <td width="200"><a href="https://arxiv.org/pdf/2012.07974.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2018 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Accelerating recurrent neural network language model based online speech recognition system</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1801.09866.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Towards Language-Universal End-to-End Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1711.02207.pdf">pdf</a></td>
                        </tr>
             </table>
            <h3> 2017 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Reducing Bias in Production Speech Models</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1705.04400.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">Exploring Speech Enhancement with Generative Adversarial Networks for Robust Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1711.05747.pdf">pdf</a></td>
                        </tr>
             </table>
        </div>
    </div>
</section>
<section class="item card-box" id="row-2">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>RNN-T</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2022 </h3>
            <table width="1150" border="1">
                <tr>
                    <td width="150" align="center">1</a></td>
                    <td width="800">Improving the fusion of acoustic and text representations in RNN-T</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.10240.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">2</a></td>
                    <td width="800">A Study of Transducer based End-to-End ASR with ESPnet: Architecture, Auxiliary Loss and Decoding Strategies</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.05420.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">3</a></td>
                    <td width="800">A Likelihood Ratio based Domain Adaptation Method for E2E Models</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.03655.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">4</a></td>
                    <td width="800">Integrating Text Inputs For Training and Adapting RNN Transducer ASR Models</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.13155.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">5</a></td>
                    <td width="800">Memory-Efficient Training of RNN-Transducer with Sampled Softmax</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16868.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">6</a></td>
                    <td width="800">Streaming parallel transducer beam search with fast-slow cascaded encoders</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.15773.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">7</a></td>
                    <td width="800">Efficient Training of Neural Transducer for Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.10586.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">8</a></td>
                    <td width="800">An Investigation of Monotonic Transducers for Large-Scale Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.08858.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">9</a></td>
                    <td width="800">A Unified Cascaded Encoder ASR Model for Dynamic Model Sizes</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.06164.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">10</a></td>
                    <td width="800">On the Prediction Network Architecture in RNN-T for ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.14618.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">11</a></td>
                    <td width="800">Pruned RNN-T for fast, memory-efficient ASR training</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.13236.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">12</a></td>
                    <td width="800">Multiple-hypothesis RNN-T Loss for Unsupervised Fine-tuning and Self-training of Neural Transducer</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.14736.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">13</a></td>
                    <td width="800">Pronunciation-aware unique character encoding for RNN Transducer-based Mandarin speech recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.14578.pdf">pdf</a></td>
                </tr>
            </table>
            <h3> 2021 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Improved Neural Language Model Fusion for Streaming Recurrent Neural Network Transducer</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2010.13878.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Streaming End-to-End Multi-Talker Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2011.13148.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800"> A Better and Faster End-to-End Model for Streaming ASR</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2011.10798.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">Tied & Reduced RNN-T Decoder</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2109.07513.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">Tiny Transducer: A Highly-efficient Speech Recognition Model on Edge Devices </td>
                            <td width="200"><a href="https://arxiv.org/pdf/2101.06856.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800"> Cascade RNN-Transducer: Syllable Based Streaming On-device Mandarin Speech Recognition with a Syllable-to-Character Converter</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2011.08469.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</a></td>
                            <td width="800">On Language Model Integration for RNN Transducer based Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.06841.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">8</a></td>
                            <td width="800">A Unified Speaker Adaptation Approach for ASR</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.08545.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">9</a></td>
                            <td width="800">Factorized Neural Transducer for Efficient Language Model Adaptation</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.01500.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">10</a></td>
                            <td width="800">Input Length Matters: An Empirical Study Of RNN-T And MWER Training For Long-form Telephony Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.03841.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">11</a></td>
                            <td width="800">Knowledge Distillation for Neural Transducers from Large Self-Supervised Pre-trained Models</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.03334.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">12</a></td>
                            <td width="800">On Language Model Integration for RNN Transducer based Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.06841.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">13</a></td>
                            <td width="800">Streaming Transformer Transducer Based Speech Recognition Using Non-Causal Convolution</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.05241.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">14</a></td>
                            <td width="800">Word-level confidence estimation for RNN transducers</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.15222.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">15</a></td>
                            <td width="800">Sequence Transduction with Graph-based Supervision</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.01272.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">16</a></td>
                            <td width="800">Joint AEC AND Beamforming with Double-Talk Detection using RNN-Transformer</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.04904.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">17</a></td>
                            <td width="800">Context-Aware Transformer Transducer for Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.03250.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">18</a></td>
                            <td width="800">Deliberation of Streaming RNN-Transducer by Non-autoregressive Decoding</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.11442.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">19</a></td>
                            <td width="800">Multi-turn RNN-T for streaming recognition of multi-party speech</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.10200.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">20</a></td>
                            <td width="800">Investigation of Training Label Error Impact on RNN-T</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.00350.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2020 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">RNN-T For Latency Controlled ASR With Improved Beam Search </td>
                            <td width="200"><a href="https://arxiv.org/pdf/1911.01629.pdf">pdf</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Transformer Transducer: A Streamable Speech Recognition Model With Transformer Encoders And RNN-T Loss</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2002.02562.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">A Streaming On-Device End-to-End Model Surpassing Server-Side Conventional Model Quality and Latency</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2003.12710.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">Towards Fast And Accurate Streaming E2E ASR</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2004.11544.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">Knowledge Distillation from Offline to Streaming RNN Transducer for End-to-end Speech Recognition</td>
                            <td width="200"><a href="https://indico2.conference4me.psnc.pl/event/35/contributions/3144/attachments/457/482/Wed-1-5-3.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800"> Transfer Learning Approaches for Streaming End-to-End Speech Recognition System</td>
                            <td width="200"><a href=https://arxiv.org/pdf/2008.05086.pdf"">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</a></td>
                            <td width="800">Analyzing the Quality and Stability of a Streaming End-to-End On-Device Speech Recognizer</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2006.01416.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">8</a></td>
                            <td width="800">Alignment Restricted Streaming Recurrent Neural Network Transducer</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2011.03072.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">9</a></td>
                            <td width="800">Benchmarking LF-MMI, CTC and RNN-T Criteria for Streaming ASR</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2011.04785.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">10</a></td>
                            <td width="800">Improving RNN transducer with normalized jointer network</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2011.01576.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">11</a></td>
                            <td width="800"> Improved Neural Language Model Fusion for Streaming Recurrent Neural Network Transducer </td>
                            <td width="200"><a href="https://arxiv.org/pdf/2010.13878.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">12</a></td>
                            <td width="800">Improving Streaming Automatic Speech Recognition With Non-Streaming Model Distillation On Unsupervised Data</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2010.12096.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">13</a></td>
                            <td width="800">FastEmit: Low-latency Streaming ASR with Sequence-level Emission Regularization </td>
                            <td width="200"><a href="https://arxiv.org/pdf/2010.11148.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">14</a></td>
                            <td width="800">Analyzing the Quality and Stability of a Streaming End-to-End On-Device Speech Recognizer </td>
                            <td width="200"><a href="https://arxiv.org/pdf/2006.01416.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">15</a></td>
                            <td width="800">Parallel Rescoring with Transformer for Streaming On-Device Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2008.13093.pdf">pdf</a></td>
                        </tr>
             </table>
            <h3> 2019 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Self-Attention Transducers for End-to-End Speech Recognition </td>
                            <td width="200"><a href="https://arxiv.org/pdf/1909.13037.pdf">pdf</a></td>
                        </tr>
             </table>
            <h3> 2018 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Streaming E2E Speech Recognition For Mobile Devices</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1811.06621.pdf">pdf</a></td>
                        </tr>
             </table>
        </div>
    </div>
</section>
<section class="item card-box" id="row-3">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>CTC</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2022 </h3>
            <table width="1150" border="1">
                <tr>
                    <td width="150" align="center">1</a></td>
                    <td width="800">Improved Mispronunciation detection system using a hybrid CTC-ATT based approach for L2 English speakers</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.10198.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">2</a></td>
                    <td width="800">Dynamic Latency for CTC-Based Streaming Automatic Speech Recognition With Emformer</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.15613.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">3</a></td>
                    <td width="800">Improving CTC-based speech recognition via knowledge transferring from pre-trained language models</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.03582.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">4</a></td>
                    <td width="800">Multistream neural architectures for cued-speech recognition using a pre-trained visual feature extractor and constrained CTC decoding</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.04965.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">5</a></td>
                    <td width="800">Adding Connectionist Temporal Summarization into Conformer to Improve Its Decoder Efficiency For Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.03889.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">6</a></td>
                    <td width="800">Better Intermediates Improve CTC Inference</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.00176.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">7</a></td>
                    <td width="800">Multi-sequence Intermediate Conditioning for CTC-based ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.00175.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">8</a></td>
                    <td width="800">InterAug: Augmenting Noisy Intermediate Predictions for CTC-based ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.00174.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">9</a></td>
                    <td width="800">Improving CTC-based ASR Models with Gated Interlayer Collaboration</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.12462.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">10</a></td>
                    <td width="800">A CTC Triggered Siamese Network with Spatial-Temporal Dropout for Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.08031.pdf">pdf</a></td>
                </tr>
            </table>
            <h3> 2021 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Why does CTC result in peaky behavior?</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2105.14849.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Non-Autoregressive Transformer ASR with CTC-Enhanced Decoder Input</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2010.15025.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">CASS-NAT: CTC Alignment-based Single Step Non-autoregressive Transformer for Speech Recognition </td>
                            <td width="200"><a href="https://arxiv.org/pdf/2010.14725.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800"> Improved Mask-CTC for Non-Autoregressive End-to-End ASR</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2010.13270.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">An Investigation of Enhancing CTC Model for Triggered Attention-based Streaming ASR</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.10402.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">Back from the future: bidirectional CTC decoding using future information in speech recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.03326.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</a></td>
                            <td width="800">CTC Variations Through New WFST Topologies</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.03098.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">8</a></td>
                            <td width="800">Hierarchical Conditional End-to-End ASR with CTC and Multi-Granular Subword Units</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.04109.pdf">pdf</a></td>
                        </tr>
             </table>
            <h3> 2020 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800"> Mask CTC: Non-Autoregressive End-to-End ASR with CTC and Mask Predict</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2005.08700.pdf">pdf</a>
                            </td>
                        </tr>
             </table>
            <h3> 2019 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Automatic Spelling Correction with Transformer for CTC-based End-to-End Speech Recognition </td>
                            <td width="200"><a href="https://arxiv.org/pdf/1904.10045.pdf">pdf</a></td>
                        </tr>
             </table>
            <h3> 2018 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">An improved hybrid CTC-Attention model for speech recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1810.12020.pdf">pdf</a></td>
                        </tr>
             </table>
            <h3> 2017 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Residual Convolutional CTC Networks for Automatic Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1702.07793.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence Labelling</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1703.00096.pdf">pdf</a></td>
                        </tr>
             </table>
        </div>
    </div>
</section>
<section class="item card-box" id="row-4">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>AED</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2022 </h3>
            <table width="1150" border="1">
                <tr>
                    <td width="150" align="center">1</a></td>
                    <td width="800">Run-and-back stitch search: novel block synchronous decoding for streaming encoder-decoder ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.10190.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">2</a></td>
                    <td width="800">USTED: Improving ASR with a Unified Speech and Text Encoder-Decoder</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.06045.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">3</a></td>
                    <td width="800">Towards Contextual Spelling Correction for Customization of End-to-end Speech Recognition Systems</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.00888.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">4</a></td>
                    <td width="800">Supervised Attention in Sequence-to-Sequence Models for Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.12308.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">5</a></td>
                    <td width="800">LegoNN: Building Modular Encoder-Decoder Models</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.03318.pdf">pdf</a></td>
                </tr>
            </table>
            <h3> 2021 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">SRU++: Pioneering Fast Recurrence with Attention for Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.05571.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">K-Wav2vec 2.0: Automatic Speech Recognition based on Joint Decoding of Graphemes and Syllables</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.05172.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">SRU++: Pioneering Fast Recurrence with Attention for Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.05571.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">Attention based end to end Speech Recognition for Voice Search in Hindi and English</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.10208.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">A Conformer-based ASR Frontend for Joint Acoustic Echo Cancellation, Speech Enhancement and Speech Separation</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.09935.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">Consistent Training and Decoding For End-to-end Speech Recognition Using Lattice-free MMI</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.02498.pdf">pdf</a></td>
                        </tr>
             </table>
            <h3> 2020 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Emformer: Efficient Memory Transformer Based Acoustic Model For Low Latency Streaming Speech Recognition </td>
                            <td width="200"><a href="https://arxiv.org/pdf/2010.10759.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">High Performance Sequence-to-Sequence Model for Streaming Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2003.10022.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</td>
                            <td width="800">Streaming Chunk-Aware Multihead Attention for Online End-to-End Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2006.01712.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</td>
                            <td width="800">Streaming Transformer-based Acoustic Models Using Self-attention with Augmented Memory </td>
                            <td width="200"><a href="https://arxiv.org/pdf/2005.08042.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</td>
                            <td width="800">CTC-synchronous Training for Monotonic Attention Model</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2005.04712.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</td>
                            <td width="800">Low Latency End-to-End Streaming Speech Recognition with a Scout Network</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2003.10369.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</td>
                            <td width="800">Synchronous Transformers For E2E Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1912.02958.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">8</td>
                            <td width="800">Transformer Online CTC/Attention E2E Speech Recognition Architecture</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2001.08290.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">9</td>
                            <td width="800">Streaming Automatic Speech Recognition With The Transformer Model</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2001.02674.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">10</td>
                            <td width="800">Minimum Latency Training Strategies For Streaming seq-to-seq ASR</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2004.05009.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">11</td>
                            <td width="800">Enhancing Monotonic Multihead Attention for Streaming ASR </td>
                            <td width="200"><a href="https://arxiv.org/pdf/2005.09394.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">12</a></td>
                            <td width="800">Multi-Encoder Learning and Stream Fusion for Transformer-Based End-to-End Automatic Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2104.00120.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">13</a></td>
                            <td width="800">Insertion-Based Modeling for End-to-End Automatic Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2005.13211.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">14</a></td>
                            <td width="800">Spike-Triggered Non-Autoregressive Transformer for End-to-End Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2005.07903.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">15</a></td>
                            <td width="800">Listen Attentively, and Spell Once: Whole Sentence Generation via a Non-Autoregressive Architecture for Low-Latency Speech Recognition </td>
                            <td width="200"><a href="https://arxiv.org/pdf/2005.04862.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">16</a></td>
                            <td width="800">Lightweight and Efficient End-to-End Speech Recognition Using Low-Rank Transformer</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1910.13923.pdf">pdf</a></td>
                        </tr>
             </table>
            <h3> 2019 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Streaming Transformer ASR with Blockwise Synchronous Inference </td>
                            <td width="200"><a href="https://arxiv.org/pdf/2006.14941.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">Triggered Attention for End-to-End Speech Recognition </td>
                            <td width="200"><a href="https://www.merl.com/publications/docs/TR2019-015.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Listen and Fill in the Missing Letters: Non-Autoregressive Transformer for Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1911.04908.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800"> Spelling Correction Model For E2E Speech Recognition </td>
                            <td width="200"><a href="https://arxiv.org/pdf/1902.07178.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800"> An Empirical Study Of Efficient ASR Rescoring With Transformers </td>
                            <td width="200"><a href="https://arxiv.org/pdf/1910.11450.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">Correction of Automatic Speech Recognition with Transformer Sequence-To-Sequence Model</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1910.10697.pdf">pdf</a></td>
                        </tr>
             </table>
            <h3> 2018 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">State-of-the-art Speech Recognition With Sequence-to-Sequence Models</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1712.01769.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">Montonic Chunkwise Attention</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1712.05382.pdf">pdf</a></td>
                        </tr>
             </table>
            <h3> 2017 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Multilingual Speech Recognition With A Single End-To-End Model</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1711.01694.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">Attention-Based End-to-End Speech Recognition in Mandarin</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1707.07167.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</td>
                            <td width="800">Recurrent Neural Aligner: An Encoder-Decoder Neural Network Model for Sequence to Sequence Mapping</td>
                            <td width="200"><a href="https://www.isca-speech.org/archive_v0/Interspeech_2017/pdfs/1705.PDF">pdf</a></td>
                        </tr>
             </table>
            <h3> 2016 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Wav2Letter: an End-to-End ConvNet-based Speech Recognition System</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1609.03193.pdf">pdf</a></td>
                        </tr>
             </table>
            <h3> 2015 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Listen, attend and spell: A neural network for large vocabulary conversational speech recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1508.01211.pdf">pdf</a></td>
                        </tr>
             </table>
        </div>
    </div>
</section>
<section class="item card-box" id="row-5">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Unified & Rescoring</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2022 </h3>
            <table width="1150" border="1">
                <tr>
                    <td width="150" align="center">1</a></td>
                    <td width="800">Two-Pass End-to-End ASR Model Compression</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.02741.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">2</a></td>
                    <td width="800">Korean Tokenization for Beam Search Rescoring in Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.03583.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">3</a></td>
                    <td width="800">WeNet 2.0: More Productive End-to-End Speech Recognition Toolkit</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.15455.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">4</a></td>
                    <td width="800">RescoreBERT: Discriminative Speech Recognition Rescoring with BERT</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.01094.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">5</a></td>
                    <td width="800">On Comparison of Encoders for Attention based End to End Speech Recognition in Standalone and Rescoring Mode</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.12829.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">6</a></td>
                    <td width="800">Two-pass Decoding and Cross-adaptation Based System Combination of End-to-end Conformer and Hybrid TDNN ASR Systems</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.11596.pdf">pdf</a></td>
                </tr>
            </table>
            <h3> 2021 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2012.05481.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">One In A Hundred: Select The Best Predicted Sequence from Numerous Candidates for Streaming Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2010.14791.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Have best of both worlds: two-pass hybrid and E2E cascading framework for speech recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.04891.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">WeNet: Production oriented Streaming and Non-streaming End-to-End Speech Recognition Toolkit</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2102.01547.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">U2++: Unified Two-pass Bidirectional End-to-end Model for Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2106.05642.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">An Investigation of Enhancing CTC Model for Triggered Attention-based Streaming ASR</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.10402.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</a></td>
                            <td width="800">ASR Rescoring and Confidence Estimation with ELECTRA</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.01857.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">8</a></td>
                            <td width="800">Have best of both worlds: two-pass hybrid and E2E cascading framework for speech recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.04891.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">9</a></td>
                            <td width="800">Rescoring Sequence-to-Sequence Models for Text Line Recognition with CTC-Prefixes</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.05909.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">10</a></td>
                            <td width="800">Lattention: Lattice-attention in ASR rescoring</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.10157.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">11</a></td>
                            <td width="800">Improving Hybrid CTC/Attention End-to-end Speech Recognition with Pretrained Acoustic and Language Model</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.07254.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">12</td>
                            <td width="800">GigaSpeech: An Evolving, Multi-domain ASR Corpus with 10,000 Hours of Transcribed Audio</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2106.06909.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">13</a></td>
                            <td width="800">ASR Rescoring and Confidence Estimation with ELECTRA</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.01857.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">14</a></td>
                            <td width="800">Have best of both worlds: two-pass hybrid and E2E cascading framework for speech recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.04891.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">15</a></td>
                            <td width="800">Rescoring Sequence-to-Sequence Models for Text Line Recognition with CTC-Prefixes</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.05909.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">16</a></td>
                            <td width="800">Lattention: Lattice-attention in ASR rescoring</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.10157.pdf">pdf</a></td>
                        </tr>
             </table>
            <h3> 2020 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Transformer Transducer: One Model Unifying Streaming And Non-Streaming Speech Recognition </td>
                            <td width="200"><a href="https://arxiv.org/pdf/2010.03192.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Universal ASR: Unify And Improve Streaming ASR With Full-Context Modeling </td>
                            <td width="200"><a href="https://openreview.net/pdf?id=Pz_dcqfcKW8">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Cascaded encoders for unifying streaming and non-streaming ASR</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2010.14606.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">Dynamic latency speech recognition with asynchronous revision</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2011.01570.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2012.05481.pdf">pdf</a></td>
                        </tr>
             </table>
            <h3> 2018 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Hybrid CTC-Attention based End-to-End Speech Recognition using Subword Units</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1807.04978.pdf">pdf</a></td>
                        </tr>
             </table>
            <h3> 2017 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Advances in Joint CTC-Attention based End-to-End Speech Recognition with a Deep CNN Encoder and RNN-LM</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1706.02737.pdf">pdf</a></td>
                        </tr>
             </table>
        </div>
    </div>
</section>
<section class="item card-box" id="row-6">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Data Aug</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2022 </h3>
            <table width="1150" border="1">
                <tr>
                    <td width="150" align="center">1</a></td>
                    <td width="800">Investigation of Data Augmentation Techniques for Disordered Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.05562.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">2</a></td>
                    <td width="800">LPC Augment: An LPC-Based ASR Data Augmentation Algorithm for Low and Zero-Resource Children's Dialects</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.09529.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">3</a></td>
                    <td width="800">Spectral Modification Based Data Augmentation For Improving End-to-End ASR For Children's Speech</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.06600.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">4</a></td>
                    <td width="800">Improving Multimodal Speech Recognition by Data Augmentation and Speech Representations</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.13206.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">5</a></td>
                    <td width="800">Auditory-Based Data Augmentation for End-to-End Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.04284.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">6</a></td>
                    <td width="800">Investigating Lexical Replacements for Arabic-English Code-Switched Data Augmentation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.12649.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">7</a></td>
                    <td width="800">Personalized Adversarial Data Augmentation for Dysarthric and Elderly Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.06445.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">8</a></td>
                    <td width="800">Improving Data Driven Inverse Text Normalization using Data Augmentation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.09674.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">9</a></td>
                    <td width="800">Data Augmentation for Low-Resource Quechua ASR Improvement</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.06872.pdf">pdf</a></td>
                </tr>
            </table>
            <h3> 2021 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">MixSpeech: Data Augmentation for Low-resource Automatic Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2102.12664.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Data Augmentation with Locally-time Reversed Speech for Automatic Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.04511.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Significance of Data Augmentation for Improving Cleft Lip and Palate Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.00797.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">Synt++: Utilizing Imperfect Synthetic Data to Improve Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.11479.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">Data Augmentation for Speech Recognition in Maltese: A Low-Resource Perspective</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.07793.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">Data Augmentation based Consistency Contrastive Pre-training for Automatic Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.12522.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</a></td>
                            <td width="800">PM-MMUT: Boosted Phone-mask Data Augmentation using Multi-modeing Unit Training for Robust Uyghur E2E Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.06721.pdf">pdf</a></td>
                        </tr>
             </table>
            <h3> 2020 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800"></td>
                            <td width="200"><a href="">pdf</a></td>
                        </tr>
             </table>
            <h3> 2019 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1904.08779.pdf">pdf</a></td>
                        </tr>
             </table>
        </div>
    </div>
</section>
<section class="item card-box" id="row-7">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>LM</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2022 </h3>
            <table width="1150" border="1">
                <tr>
                    <td width="150" align="center">1</a></td>
                    <td width="800">Neural-FST Class Language Model for End-to-End Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.11867.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">2</a></td>
                    <td width="800">Improving Mandarin End-to-End Speech Recognition with Word N-gram Language Model</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.01995.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">3</a></td>
                    <td width="800">Language technology practitioners as language managers: arbitrating data bias and predictive bias in ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.12603.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">4</a></td>
                    <td width="800">Knowledge Transfer from Large-scale Pretrained Language Models to End-to-end Speech Recognizers</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.07894.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">5</a></td>
                    <td width="800">A practical framework for multi-domain speech recognition and an instance sampling method to neural language modeling</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.04767.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">6</a></td>
                    <td width="800">An Empirical Study of Language Model Integration for Transducer based Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16776.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">7</a></td>
                    <td width="800">Improving Speech Recognition for Indic Languages using Language Model</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16595.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">8</a></td>
                    <td width="800">Sentence-Select: Large-Scale Language Model Data Selection for Rare-Word Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.05008.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">9</a></td>
                    <td width="800">Detecting Unintended Memorization in Language-Model-Fused ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.09606.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">10</a></td>
                    <td width="800">Improving Rare Word Recognition with LM-aware MWER Training</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.07553.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">11</a></td>
                    <td width="800">Effect and Analysis of Large-scale Language Model Rescoring on Competitive ASR Systems</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.00212.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">12</a></td>
                    <td width="800">Contextual Density Ratio for Language Model Biasing of Sequence to Sequence ASR Systems</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.14623.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">13</a></td>
                    <td width="800">Distilling a Pretrained Language Model to a Multilingual ASR Model</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.12638.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">14</a></td>
                    <td width="800">Residual Language Model for End-to-end Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.07430.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">15</a></td>
                    <td width="800">ASR-Generated Text for Language Model Pre-training Applied to Speech Tasks</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.01893.pdf">pdf</a></td>
                </tr>
            </table>
            <h3> 2021 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Private Language Model Adaptation for Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.10026.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Disambiguation-BERT for N-best Rescoring in Low-Resource Conversational ASR</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.02267.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Internal Language Model Adaptation with Text-Only Data for End-to-End Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.05354.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">Learning Domain Specific Language Models for Automatic Speech Recognition through Machine Translation</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.10261.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">Private Language Model Adaptation for Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.10026.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">ViraPart: A Text Refinement Framework for ASR and NLP Tasks in Persian</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.09086.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</a></td>
                            <td width="800">Conversational speech recognition leveraging effective fusion methods for cross-utterance language modeling</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.03333.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">8</a></td>
                            <td width="800">Mixed Precision of Quantization of Transformer Language Models for Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.11540.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">9</a></td>
                            <td width="800">Mixed Precision Low-bit Quantization of Neural Network Language Models for Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.11438.pdf">pdf</a></td>
                        </tr>
             </table>
        </div>
    </div>
</section>
<section class="item card-box" id="row-8">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Unsupervised</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2022 </h3>
            <table width="1150" border="1">
                <tr>
                    <td width="150" align="center">1</a></td>
                    <td width="800">A Noise-Robust Self-supervised Pre-training Model Based Speech Representation Learning for Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.08930.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">2</a></td>
                    <td width="800">Robust Self-Supervised Audio-Visual Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.01763.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">3</a></td>
                    <td width="800">Learning Audio-Visual Speech Representation by Masked Multimodal Cluster Prediction</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.02184.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">4</a></td>
                    <td width="800">IQDUBBING: Prosody modeling based on discrete self-supervised speech representation for expressive voice conversion</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.00269.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">5</a></td>
                    <td width="800">Learning Contextually Fused Audio-visual Representations for Audio-visual Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.07428.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">6</a></td>
                    <td width="800">Efficient Adapter Transfer of Self-Supervised Speech Models for Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.03218.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">7</a></td>
                    <td width="800">Self-supervised Learning with Random-projection Quantizer for Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.01855.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">8</a></td>
                    <td width="800">The CORAL++ Algorithm for Unsupervised Domain Adaptation of Speaker Recogntion</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.01092.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">9</a></td>
                    <td width="800">Autoregressive Co-Training for Learning Discrete Speech Representations</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.15840.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">10</a></td>
                    <td width="800">Language Adaptive Cross-lingual Speech Representation Learning with Sparse Sharing Sub-networks</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.04583.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">11</a></td>
                    <td width="800">Learning Audio Representations with MLPs</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.08490.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">12</a></td>
                    <td width="800">Privacy-Preserving Speech Representation Learning using Vector Quantization</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.09518.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">13</a></td>
                    <td width="800">Probing phoneme, language and speaker information in unsupervised speech representations</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16193.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">14</a></td>
                    <td width="800">TRILLsson: Distilled Universal Paralinguistic Speech Representations</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.00236.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">15</a></td>
                    <td width="800">XTREME-S: Evaluating Cross-lingual Speech Representations</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.10752.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">16</a></td>
                    <td width="800">A Brief Overview of Unsupervised Neural Speech Representation Learning</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.01829.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">17</a></td>
                    <td width="800">Analyzing the factors affecting usefulness of Self-Supervised Pre-trained Representations for Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16973.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">18</a></td>
                    <td width="800">Audio Self-supervised Learning: A Survey</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.01205.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">19</a></td>
                    <td width="800">Federated Domain Adaptation for ASR with Full Self-Supervision</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.15966.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">20</a></td>
                    <td width="800">Improving Mispronunciation Detection with Wav2vec2-based Momentum Pseudo-Labeling for Accentedness and Intelligibility Assessment</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.15937.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">21</a></td>
                    <td width="800">Investigating Self-supervised Pretraining Frameworks for Pathological Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.15431.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">22</a></td>
                    <td width="800">Leveraging Unimodal Self-Supervised Learning for Multimodal Audio-Visual Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.07996.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">23</a></td>
                    <td width="800">LightHuBERT: Lightweight and Configurable Speech Representation Learning with Once-for-All Hidden-Unit BERT</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.15610.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">24</a></td>
                    <td width="800">Pre-Training Transformer Decoder for End-to-End ASR Model with Unpaired Speech Data</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.17113.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">25</a></td>
                    <td width="800">Towards Representative Subset Selection for Self-Supervised Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.09829.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">26</a></td>
                    <td width="800">Unsupervised Word Segmentation using K Nearest Neighbors</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.13094.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">27</a></td>
                    <td width="800">Masked Spectrogram Prediction For Self-Supervised Audio Pre-Training</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.12768.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">28</a></td>
                    <td width="800">Why does Self-Supervised Learning for Speech Recognition Benefit Speaker Recognition?</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.12765.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">29</a></td>
                    <td width="800">Masked Spectrogram Modeling using Masked Autoencoders for Learning General-purpose Audio Representation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.12260.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">30</a></td>
                    <td width="800">ATST: Audio Representation Learning with Teacher-Student Transformer</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.12076.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">31</a></td>
                    <td width="800">Improving Self-Supervised Speech Representations by Disentangling Speakers</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.09224.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">32</a></td>
                    <td width="800">BYOL for Audio: Exploring Pre-trained General-purpose Audio Representations</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.07402.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">33</a></td>
                    <td width="800">HuBERT-EE: Early Exiting HuBERT for Efficient Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.06328.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">34</a></td>
                    <td width="800">Can Self-Supervised Learning solve the problem of child speech recognition?</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.05419.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">35</a></td>
                    <td width="800">Unsupervised Uncertainty Measures of Automatic Speech Recognition for Non-intrusive Speech Intelligibility Prediction</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.04288.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">36</a></td>
                    <td width="800">Automatic Pronunciation Assessment using Self-Supervised Speech Representation Learning</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.03863.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">37</a></td>
                    <td width="800">Federated Self-supervised Speech Representations: Are We There Yet?</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.02804.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">38</a></td>
                    <td width="800">Towards End-to-end Unsupervised Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.02492.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">39</a></td>
                    <td width="800">Combining Spectral and Self-Supervised Features for Low Resource Speech Recognition and Translation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.02470.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">40</a></td>
                    <td width="800">Disentangled Speech Representation Learning Based on Factorized Hierarchical Variational Autoencoder with Self-Supervised Objective</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.02166.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">41</a></td>
                    <td width="800">Unsupervised Data Selection via Discrete Speech Representation for ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.01981.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">42</a></td>
                    <td width="800">Self-Supervised Speech Representations Preserve Speech Characteristics while Anonymizing Voices</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.01677.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">43</a></td>
                    <td width="800">Cross-lingual Self-Supervised Speech Representations for Improved Dysarthric Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.01670.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">44</a></td>
                    <td width="800">A Study of Gender Impact in Self-supervised Models for Speech-to-Text Systems</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.01397.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">45</a></td>
                    <td width="800">Contrastive Siamese Network for Semi-supervised Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.14054.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">46</a></td>
                    <td width="800">Joint Training of Speech Enhancement and Self-supervised Model for Noise-robust ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.13293.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">47</a></td>
                    <td width="800">Deploying self-supervised learning in the wild for hybrid automatic speech recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.08598.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">48</a></td>
                    <td width="800">Self-Supervised Speech Representation Learning: A Review</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.10643.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">49</a></td>
                    <td width="800">SQ-VAE: Variational Bayes on Discrete Representation with Self-annealed Stochastic Quantization</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.07547.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">50</a></td>
                    <td width="800">Improved Consistency Training for Semi-Supervised Sequence-to-Sequence ASR via Speech Chain Reconstruction and Self-Transcribing</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.06963.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">51</a></td>
                    <td width="800">Wav2Seq: Pre-training Speech-to-Text Encoder-Decoder Models Using Pseudo Languages</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.01086.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">52</a></td>
                    <td width="800">Boosting Cross-Domain Speech Recognition with Self-Supervision</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.09783.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">53</a></td>
                    <td width="800">Censer: Curriculum Semi-supervised Learning for Speech Recognition Based on Self-supervised Pre-training</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.08189.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">54</a></td>
                    <td width="800">Censer: Curriculum Semi-supervised Learning for Speech Recognition Based on Self-supervised Pre-training</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.08189.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">55</a></td>
                    <td width="800">DRAFT: A Novel Framework to Reduce Domain Shifting in Self-supervised Learning and Its Application to Children's ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.07931.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">56</a></td>
                    <td width="800">FeaRLESS: Feature Refinement Loss for Ensembling Self-Supervised Learning Features in Robust End-to-end Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.15056.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">57</a></td>
                    <td width="800">Investigation of Ensemble features of Self-Supervised Pretrained Models for Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.05518.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">58</a></td>
                    <td width="800">Joint Encoder-Decoder Self-Supervised Pre-training for ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.04465.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">59</a></td>
                    <td width="800">Predicting within and across language phoneme recognition performance of self-supervised learning speech pre-trained models</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.12489.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">60</a></td>
                    <td width="800">Wav2Vec-Aug: Improved self-supervised training with limited data</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.13654.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">61</a></td>
                    <td width="800">Learning Phone Recognition from Unpaired Audio and Phone Sequences Based on Generative Adversarial Network</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.14568.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">62</a></td>
                    <td width="800">Domain Specific Wav2vec 2.0 Fine-tuning For The SE&R 2022 Challenge</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.14418.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">63</a></td>
                    <td width="800">Unsupervised data selection for Speech Recognition with contrastive loss ratios</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.12028.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">64</a></td>
                    <td width="800">Speaker consistency loss and step-wise optimization for semi-supervised joint training of TTS and ASR using unpaired text data</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.04659.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">65</a></td>
                    <td width="800">Improving Low-Resource Speech Recognition with Pretrained Speech Models: Continued Pretraining vs. Semi-Supervised Training</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.00659.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">66</a></td>
                    <td width="800">FitHuBERT: Going Thinner and Deeper for Knowledge Distillation of Speech Self-Supervised Learning</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.00555.pdf">pdf</a></td>
                </tr>
            </table>
            <h3> 2021 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Private Language Model Adaptation for Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.10026.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Analyzing the Robustness of Unsupervised Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.03509.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Combining Unsupervised and Text Augmented Semi-Supervised Learning for Low Resourced Autoregressive Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.15836.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">Large-scale ASR Domain Adaptation using Self- and Semi-supervised Learning</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.00165.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">Wav2vec-S: Semi-Supervised Pre-Training for Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.04484.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.13900.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</a></td>
                            <td width="800">Unsupervised Speech Enhancement with speech recognition embedding and disentanglement losses</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.08678.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">8</a></td>
                            <td width="800">Semi-supervised transfer learning for language expansion of end-to-end speech recognition models to low-resource languages</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.10047.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">9</a></td>
                            <td width="800">Self-Supervised Learning for speech recognition with Intermediate layer supervision</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.08778.pdf">pdf</a></td>
                        </tr>
             </table>
        </div>
    </div>
</section>
<section class="item card-box" id="row-9">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Multilingual</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2022 </h3>
            <table width="1150" border="1">
                <tr>
                    <td width="150" align="center">1</a></td>
                    <td width="800">Reducing language context confusion for end-to-end code-switching automatic speech recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.12155.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">2</a></td>
                    <td width="800">Discovering Phonetic Inventories with Crosslingual Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.11207.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">3</a></td>
                    <td width="800">Data and knowledge-driven approaches for multilingual training to improve the performance of speech recognition systems of Indian languages</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.09494.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">4</a></td>
                    <td width="800">A Survey of Multilingual Models for Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.12576.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">5</a></td>
                    <td width="800">Code Switched and Code Mixed Speech Recognition for Indic languages</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16578.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">6</a></td>
                    <td width="800">Frequency-Directional Attention Model for Multilingual Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.15473.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">7</a></td>
                    <td width="800">Hierarchical Softmax for End-to-End Low-resource Multilingual Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.03855.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">8</a></td>
                    <td width="800">Adaptive Activation Network For Low Resource Multilingual Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.14326.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">9</a></td>
                    <td width="800">Bilingual End-to-End ASR with Byte-Level Subwords</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.00485.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">10</a></td>
                    <td width="800">LAE: Language-Aware Encoder for Monolingual and Multilingual ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.02093.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">11</a></td>
                    <td width="800">Language-specific Characteristic Assistance for Code-switching Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.14580.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">12</a></td>
                    <td width="800">Internal Language Model Estimation based Language Model Fusion for Cross-Domain Code-Switching Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.04176.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">13</a></td>
                    <td width="800">Investigating the Impact of Cross-lingual Acoustic-Phonetic Similarities on Multilingual Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.03390.pdf">pdf</a></td>
                </tr>
            </table>
            <h3> 2021 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">GigaSpeech: An Evolving, Multi-domain ASR Corpus with 10,000 Hours of Transcribed Audio</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2106.06909.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Magic dust for cross-lingual adaptation of monolingual wav2vec-2.0</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.03560.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Mandarin-English Code-switching Speech Recognition with Self-supervised Speech Representation Models</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.03504.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">Minimum word error training for non-autoregressive Transformer-based code-switching ASR</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.03573.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">Multilingual Speech Recognition using Knowledge Transfer across Learning Processes</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.07909.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">Joint Unsupervised and Supervised Training for Multilingual ASR</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.08137.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</a></td>
                            <td width="800">Joint Modeling of Code-Switched and Monolingual ASR via Conditional Factorization</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.08137.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">8</a></td>
                            <td width="800">Bilingual Speech Recognition by Estimating Speaker Geometry from Video Data</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.13463.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">9</a></td>
                            <td width="800">Integrating Knowledge in End-to-End Automatic Speech Recognition for Mandarin-English Code-Switching</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.10202.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">10</a></td>
                            <td width="800">Building a great multi-lingual teacher with sparsely-gated mixture of experts for speech recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.05820.pdf">pdf</a></td>
                        </tr>
             </table>
        </div>
    </div>
</section>
<section class="item card-box" id="row-10">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Personal</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2022 </h3>
            <table width="1150" border="1">
                <tr>
                    <td width="150" align="center">1</a></td>
                    <td width="800">ProtoSound: A Personalized and Scalable Sound Recognition System for Deaf and Hard-of-Hearing Users</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.11134.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">2</a></td>
                    <td width="800">Speaker Adaptation Using Spectro-Temporal Deep Features for Dysarthric and Elderly Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.10290.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">3</a></td>
                    <td width="800">Domain Adaptation of low-resource Target-Domain models using well-trained ASR Conformer Models</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.09167.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">4</a></td>
                    <td width="800">End-to-end contextual asr based on posterior distribution adaptation for hybrid ctc/attention system</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.09003.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">5</a></td>
                    <td width="800">Curriculum optimization for low-resource speech recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.08883.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">6</a></td>
                    <td width="800">Enhancing ASR for Stuttered Speech with Limited Data Using Detect and Pass</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.05396.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">7</a></td>
                    <td width="800">Improving Automatic Speech Recognition for Non-Native English with Transfer Learning and Language Model Decoding</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.05209.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">8</a></td>
                    <td width="800">Listen, Adapt, Better WER: Source-free Single-utterance Test-time Adaptation for Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.14222.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">9</a></td>
                    <td width="800">PADA: Pruning Assisted Domain Adaptation for Self-Supervised Speech Representations</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16965.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">10</a></td>
                    <td width="800">Using Adapters to Overcome Catastrophic Forgetting in End-to-End Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16082.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">11</a></td>
                    <td width="800">Speaker adaptation for Wav2vec2 based dysarthric ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.0077.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">12</a></td>
                    <td width="800">Contextual Adapters for Personalized Speech Recognition in Neural Transducers</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.13660.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">13</a></td>
                    <td width="800">Adaptive multilingual speech recognition with pretrained models</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.12304.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">14</a></td>
                    <td width="800">A Simple Baseline for Domain Adaptation in End to End ASR Systems Using Synthetic Data</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.13240.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">15</a></td>
                    <td width="800">Confidence Score Based Conformer Speaker Adaptation for Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.12045.pdf">pdf</a></td>
                </tr>
            </table>
            <h3> 2021 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">GigaSpeech: An Evolving, Multi-domain ASR Corpus with 10,000 Hours of Transcribed Audio</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2106.06909.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Fast Contextual Adaptation with Neural Associative Memory for On-Device Personalized Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.02220.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Personalized Automatic Speech Recognition Trained on Small Disordered Speech Datasets</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.04612.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">Personalizing ASR with limited data using targeted subset selection</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.04908.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">Prompt-tuning in ASR systems for efficient domain-adaptation</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.06502.pdf">pdf</a></td>
                        </tr>
             </table>
        </div>
    </div>
</section>
<section class="item card-box" id="row-11">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Accent</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2022 </h3>
            <table width="1150" border="1">
                <tr>
                    <td width="150" align="center">1</a></td>
                    <td width="800">Investigation of Deep Neural Network Acoustic Modelling Approaches for Low Resource Accented Mandarin Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.09432.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">2</a></td>
                    <td width="800">Layer-wise Fast Adaptation for End-to-End Multi-Accent Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.09883.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">3</a></td>
                    <td width="800">Deep Speech Based End-to-End Automated Speech Recognition (ASR) for Indian-English Accents</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.00977.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">4</a></td>
                    <td width="800">Cleanformer: A microphone array configuration-invariant, streaming, multichannel neural enhancement frontend for ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.11933.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">5</a></td>
                    <td width="800">Accented Speech Recognition: Benchmarking, Pre-training, and Diverse Data</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.08014.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">6</a></td>
                    <td width="800">A Highly Adaptive Acoustic Model for Accurate Multi-Dialect Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.03027.pdf">pdf</a></td>
                </tr>
            </table>
            <h3> 2021 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">GigaSpeech: An Evolving, Multi-domain ASR Corpus with 10,000 Hours of Transcribed Audio</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2106.06909.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Accent-Robust Automatic Speech Recognition Using Supervised and Unsupervised Wav2vec Embeddings</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.06502.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Multi-Dialect Arabic Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.14678.pdf">pdf</a></td>
                        </tr>
             </table>
        </div>
    </div>
</section>
<section class="item card-box" id="row-12">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Dataset</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2022 </h3>
            <table width="1150" border="1">
                <tr>
                    <td width="150" align="center">1</a></td>
                    <td width="800">The Norwegian Parliamentary Speech Corpus</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.10881.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">2</a></td>
                    <td width="800">CI-AVSR: A Cantonese Audio-Visual Speech Dataset for In-car Command Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.03804.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">3</a></td>
                    <td width="800">Automatic Speech Recognition Datasets in Cantonese: A Survey and New Dataset</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.02419.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">4</a></td>
                    <td width="800">Finnish Parliament ASR corpus - Analysis, benchmarks and statistics</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.14876.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">5</a></td>
                    <td width="800">Lahjoita puhetta -- a large-scale corpus of spoken Finnish with some benchmarks</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.12906.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">6</a></td>
                    <td width="800">Open Source MagicData-RAMC: A Rich Annotated Mandarin Conversational(RAMC) Speech Dataset</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16844.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">7</a></td>
                    <td width="800">GigaST: A 10,000-hour Pseudo Speech Translation Corpus</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.03939.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">8</a></td>
                    <td width="800">GWA: A Large High-Quality Acoustic Dataset for Audio Processing</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.01787.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">9</a></td>
                    <td width="800">SDS-200: A Swiss German Speech to Standard German Text Corpus</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.09501.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">10</a></td>
                    <td width="800">Annotated Speech Corpus for Low Resource Indian Languages: Awadhi, Bhojpuri, Braj and Magahi</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.12931.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">11</a></td>
                    <td width="800">Bengali Common Voice Speech Dataset for Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.14053.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">12</a></td>
                    <td width="800">TALCS: An Open-Source Mandarin-English Code-Switching Corpus and a Speech Recognition Baseline</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.13135.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">13</a></td>
                    <td width="800">The Makerere Radio Speech Corpus: A Luganda Radio Corpus for Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.0979.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">14</a></td>
                    <td width="800">Huqariq: A Multilingual Speech Corpus of Native Languages of Peru for Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.05498.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">15</a></td>
                    <td width="800">UserLibri: A Dataset for ASR Personalization Using Only Text</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.00706.pdf">pdf</a></td>
                </tr>
            </table>
            <h3> 2021 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">GigaSpeech: An Evolving, Multi-domain ASR Corpus with 10,000 Hours of Transcribed Audio</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2106.06909.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Building a Noisy Audio Dataset to Evaluate Machine Learning Approaches for Automatic Speech Recognition Systems</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.01425.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">CORAA: a large corpus of spontaneous and prepared speech manually validated for speech recognition in Brazilian Portuguese</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.15731.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">WenetSpeech: A 10000+ Hours Multi-domain Mandarin Corpus for Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.03370.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">Towards Measuring Fairness in Speech Recognition: Casual Conversations Dataset Transcriptions</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.09983.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">The People's Speech: A Large-Scale Diverse English Speech Recognition Dataset for Commercial Usage</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.09344.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</a></td>
                            <td width="800">JTubeSpeech: corpus of Japanese speech collected from YouTube for speech recognition and speaker verification</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.09323.pdf">pdf</a></td>
                        </tr>
             </table>
        </div>
    </div>
</section>
<section class="item card-box" id="row-13">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Robust</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2022 </h3>
            <table width="1150" border="1">
                <tr>
                    <td width="150" align="center">1</a></td>
                    <td width="800">A Conformer Based Acoustic Model for Robust Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.00725.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">2</a></td>
                    <td width="800">Dual-Path Style Learning for End-to-End Noise-Robust Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.14838.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">3</a></td>
                    <td width="800">Noise-robust Speech Recognition with 10 Minutes Unparalleled In-domain Data</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.15321.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">4</a></td>
                    <td width="800">RED-ACE: Robust Error Detection for ASR using Confidence Embeddings</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.07172.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">5</a></td>
                    <td width="800">Speech-enhanced and Noise-aware Networks for Robust Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.13696.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">6</a></td>
                    <td width="800">Mask scalar prediction for improving robust automatic speech recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.12092.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">7</a></td>
                    <td width="800">Hear No Evil: Towards Adversarial Robustness of Automatic Speech Recognition via Multi-Task Learning</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.02381.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">8</a></td>
                    <td width="800">Calibrate and Refine! A Novel and Agile Framework for ASR-error Robust Intent Detection</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.11008.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">9</a></td>
                    <td width="800">Speaker Reinforcement Using Target Source Extraction for Robust Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.04433.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">10</a></td>
                    <td width="800">Transfer Learning for Robust Low-Resource Children's Speech ASR with Transformers and Source-Filter Warping</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.09396.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">11</a></td>
                    <td width="800">ESPnet-SE++: Speech Enhancement for Robust Speech Recognition, Translation, and Understanding</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.09514.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">12</a></td>
                    <td width="800">pMCT: Patched Multi-Condition Training for Robust Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.04949.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">13</a></td>
                    <td width="800">DEFORMER: Coupling Deformed Localized Patterns with Global Context for Robust End-to-end Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.01732.pdf">pdf</a></td>
                </tr>
            </table>
            <h3> 2021 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Robustifying automatic speech recognition by extracting slowly varying features</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.07400.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">Perceptual Loss with Recognition Model for Single-Channel Enhancement and Robust ASR</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.06068.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</td>
                            <td width="800">Sequential Randomized Smoothing for Adversarially Robust Speech Recognition</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.03000.pdf">pdf</a></td>
                        </tr>
             </table>
        </div>
    </div>
</section>
<section class="item card-box" id="row-14">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Speaker Diarization</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2022 </h3>
            <table width="1150" border="1">
                <tr>
                    <td width="150" align="center">1</a></td>
                    <td width="800">ASR-Aware End-to-end Neural Diarization</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.01286.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">2</a></td>
                    <td width="800">Royalflush Speaker Diarization System for ICASSP 2022 Multi-channel Multi-party Meeting Transcription Challenge</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.04814.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">3</a></td>
                    <td width="800">The CUHK-TENCENT speaker diarization system for the ICASSP 2022 multi-channel multi-party meeting transcription challenge</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.01986.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">4</a></td>
                    <td width="800">EEND-SS: Joint End-to-End Neural Speaker Diarization and Speech Separation for Flexible Number of Speakers</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.17068.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">5</a></td>
                    <td width="800">Multi-scale Speaker Diarization with Dynamic Scale Weighting</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.15974.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">6</a></td>
                    <td width="800">Multi-Target Filter and Detector for Speaker Diarization</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16007.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">7</a></td>
                    <td width="800">Speaker Embedding-aware Neural Diarization: an Efficient Framework for Overlapping Speech Diarization in Meeting Scenarios</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.09767.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">8</a></td>
                    <td width="800">Improving the Naturalness of Simulated Conversations for End-to-End Neural Diarization</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.11232.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">9</a></td>
                    <td width="800">Robust End-to-end Speaker Diarization with Generic Neural Clustering</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.08164.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">10</a></td>
                    <td width="800">Self-supervised Speaker Diarization</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.04166.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">11</a></td>
                    <td width="800">From Simulated Mixtures to Simulated Conversations as Training Data for End-to-End Neural Diarization</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.00890.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">12</a></td>
                    <td width="800">Multimodal Clustering with Role Induced Constraints for Speaker Diarization</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.00657.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">13</a></td>
                    <td width="800">Bi-LSTM Scoring Based Similarity Measurement with Agglomerative Hierarchical Clustering (AHC) for Speaker Diarization</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.09709.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">14</a></td>
                    <td width="800">PRISM: Pre-trained Indeterminate Speaker Representation Model for Speaker Diarization and Speaker Verification</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.07450.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">15</a></td>
                    <td width="800">Interrelate Training and Searching: A Unified Online Clustering Framework for Speaker Diarization</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.13760.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">16</a></td>
                    <td width="800">Online Neural Diarization of Unlimited Numbers of Speakers</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.02432.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">17</a></td>
                    <td width="800">Utterance-by-utterance overlap-aware neural diarization with Graph-PIT</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.13888.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">18</a></td>
                    <td width="800">Online Target Speaker Voice Activity Detection for Speaker Diarization</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.05920.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">19</a></td>
                    <td width="800">Tandem Multitask Training of Speaker Diarisation and Speech Recognition for Meeting Transcription</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.03852.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">20</a></td>
                    <td width="800">Speaker Diarization and Identification from Single-Channel Classroom Audio Recording Using Virtual Microphones</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.00660.pdf">pdf</a></td>
                </tr>
            </table>
        </div>
    </div>
</section>

<section class="item card-box" id="row-15">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>MultiChannel</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2022 </h3>
            <table width="1150" border="1">
                <tr>
                    <td width="150" align="center">1</a></td>
                    <td width="800">Summary On The ICASSP 2022 Multi-Channel Multi-Party Meeting Transcription Grand Challenge</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.03647.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">2</a></td>
                    <td width="800">The USTC-Ximalaya system for the ICASSP 2022 multi-channel multi-party meeting transcription (M2MeT) challenge</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.04855.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">3</a></td>
                    <td width="800">Royalflush Speaker Diarization System for ICASSP 2022 Multi-channel Multi-party Meeting Transcription Challenge</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.04814.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">4</a></td>
                    <td width="800">The Volcspeech system for the ICASSP 2022 multi-channel multi-party meeting transcription challenge</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.04261.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">5</a></td>
                    <td width="800">Exploiting Single-Channel Speech for Multi-Channel End-to-End Speech Recognition: A Comparative Study</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16757.pdf">pdf</a></td>
                </tr>
            </table>
        </div>
    </div>
</section>

<section class="item card-box" id="row-16">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>MultiModal</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2022 </h3>
            <table width="1150" border="1">
                <tr>
                    <td width="150" align="center">1</a></td>
                    <td width="800">Improved Meta Learning for Low Resource Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.06182.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">2</a></td>
                    <td width="800">A Closer Look at Audio-Visual Multi-Person Speech Recognition and Active Speaker Selection</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.05684.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">3</a></td>
                    <td width="800">End-to-End Multi-Person Audio/Visual Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.05586.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">4</a></td>
                    <td width="800">AVATAR: Unconstrained Audiovisual Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.07684.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">5</a></td>
                    <td width="800">Exploiting Cross-domain And Cross-Lingual Ultrasound Tongue Imaging Features For Elderly And Dysarthric Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.07327.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">6</a></td>
                    <td width="800">Self-supervised Learning of Audio Representations from Audio-Visual Data using Spatial Alignment</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.00970.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">7</a></td>
                    <td width="800">SoundSpaces 2.0: A Simulation Platform for Visual-Acoustic Learning</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.08312.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">8</a></td>
                    <td width="800">Towards Generalisable Audio Representations for Audio-Visual Navigation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.00393.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">9</a></td>
                    <td width="800">Visual Context-driven Audio Feature Enhancement for Robust End-to-End Audio-Visual Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.06020.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">10</a></td>
                    <td width="800">Kaggle Competition: Cantonese Audio-Visual Speech Recognition for In-car Commands</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.02663.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">11</a></td>
                    <td width="800">Leveraging Acoustic Contextual Representation by Audio-textual Cross-modal Learning for Conversational ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.01039.pdf">pdf</a></td>
                </tr>
            </table>
        </div>
    </div>
</section>


<section class="item card-box" id="row-17">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Speech translation</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2022 </h3>
            <table width="1150" border="1">
                <tr>
                    <td width="150" align="center">1</a></td>
                    <td width="800">Who Are We Talking About? Handling Person Names in Speech Translation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.06755.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">2</a></td>
                    <td width="800">Multiformer: A Head-Configurable Transformer-Based Model for Direct Speech Translation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.07100.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">3</a></td>
                    <td width="800">Efficient yet Competitive Speech Translation: FBK@IWSLT2022</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.02629.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">4</a></td>
                    <td width="800">Cross-modal Contrastive Learning for Speech Translation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.02444.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">5</a></td>
                    <td width="800">ON-TRAC Consortium Systems for the IWSLT 2022 Dialect and Low-resource Speech Translation Tasks</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.01987.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">6</a></td>
                    <td width="800">Non-Parametric Domain Adaptation for End-to-End Speech Translation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.11211.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">7</a></td>
                    <td width="800">On the Impact of Noises in Crowd-Sourced Data for Speech Translation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.13756.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">8</a></td>
                    <td width="800">Over-Generation Cannot Be Rewarded: Length-Adaptive Average Lagging for Simultaneous Speech Translation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.05807.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">9</a></td>
                    <td width="800">Revisiting End-to-End Speech-to-Text Translation From Scratch</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.04571.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">10</a></td>
                    <td width="800">The YiTrans End-to-End Speech Translation System for IWSLT 2022 Offline Shared Task</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.05777.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">11</a></td>
                    <td width="800">M-Adapter: Modality Adaptation for End-to-End Speech-to-Text Translation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.00952.pdf">pdf</a></td>
                </tr>
            </table>
        </div>
    </div>
</section>




<section class="item card-box" id="row-18">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Other</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2022 </h3>
            <table width="1150" border="1">
                <tr>
                    <td width="150" align="center">1</a></td>
                    <td width="800">Endpoint Detection for Streaming End-to-End Multi-talker ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.09979.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">2</a></td>
                    <td width="800">How Bad Are Artifacts?: Analyzing the Impact of Speech Enhancement Errors on ASR</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.06685.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">3</a></td>
                    <td width="800">Comparative Study of Acoustic Echo Cancellation Algorithms for Speech Recognition System in Noisy Environment</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.06209.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">4</a></td>
                    <td width="800">Spectro-Temporal Deep Features for Disordered Speech Assessment and Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.05554.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">5</a></td>
                    <td width="800">Learning to Enhance or Not: Neural Network-Based Switching of Enhanced and Observed Signals for Overlapping Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.03881.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">6</a></td>
                    <td width="800">Cross-Modal ASR Post-Processing System for Error Correction and Utterance Rejection</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2201.03313.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">7</a></td>
                    <td width="800">Towards Better Meta-Initialization with Task Augmentation for Kindergarten-aged Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.12326.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">8</a></td>
                    <td width="800">Adversarial Attacks on Speech Recognition Systems for Mission-Critical Applications: A Survey</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.10594.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">9</a></td>
                    <td width="800">VADOI:Voice-Activity-Detection Overlapping Inference For End-to-end Long-form Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.10593.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">10</a></td>
                    <td width="800">Mitigating Closed-model Adversarial Examples with Bayesian Neural Modeling for Enhanced End-to-End Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.08532.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">11</a></td>
                    <td width="800">ASRPU: A Programmable Accelerator for Low-Power Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.04971.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">12</a></td>
                    <td width="800">A two-step approach to leverage contextual data: speech recognition in air-traffic communications</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.03725.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">13</a></td>
                    <td width="800">Semantic-aware Speech to Text Transmission with Redundancy Removal</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.03211.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">14</a></td>
                    <td width="800">Joint Speech Recognition and Audio Captioning</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.01405.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">15</a></td>
                    <td width="800">Error Correction in ASR using Sequence-to-Sequence Models</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.01157.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">16</a></td>
                    <td width="800">Visualizing Automatic Speech Recognition -- Means for a Better Understanding?</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.00673.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">17</a></td>
                    <td width="800">BEA-Base: A Benchmark for ASR of Spontaneous Hungarian</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.00601.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">18</a></td>
                    <td width="800">Language Dependencies in Adversarial Attacks on Speech Recognition Systems</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2202.00399.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">19</a></td>
                    <td width="800">Analysis of EEG frequency bands for Envisioned Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.15250.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">20</a></td>
                    <td width="800">Attacks as Defenses: Designing Robust Audio CAPTCHAs Using Attacks on Automatic Speech Recognition Systems</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.05408.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">21</a></td>
                    <td width="800">Automatic Speech recognition for Speech Assessment of Preschool Children</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.12886.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">22</a></td>
                    <td width="800">Building Robust Spoken Language Understanding by Cross Attention between Phoneme Sequence and ASR Hypothesis</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.12067.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">23</a></td>
                    <td width="800">Computing Optimal Location of Microphone for Improved Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.13259.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">24</a></td>
                    <td width="800">Effectiveness of text to speech pseudo labels for forced alignment and cross lingual pretrained models for low resource speech recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16823.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">25</a></td>
                    <td width="800">Exploiting Cross Domain Acoustic-to-articulatory Inverted Features For Disordered Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.10274.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">26</a></td>
                    <td width="800">How Does Pre-trained Wav2Vec2.0 Perform on Domain Shifted ASR? An Extensive Benchmark on Air Traffic Control Communications</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16822.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">27</a></td>
                    <td width="800">Impact of Dataset on Acoustic Models for Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.13590.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">28</a></td>
                    <td width="800">indic-punct: An automatic punctuation restoration and inverse text normalization framework for Indic languages</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16825.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">29</a></td>
                    <td width="800">Integrate Lattice-Free MMI into End-to-End Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.15614.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">30</a></td>
                    <td width="800">Is Word Error Rate a good evaluation metric for Speech Recognition in Indic Languages?</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16601.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">31</a></td>
                    <td width="800">Measuring the Impact of Individual Domain Factors in Self-Supervised Pre-Training</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.00648.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">32</a></td>
                    <td width="800">Mel Frequency Spectral Domain Defenses against Adversarial Attacks on Speech Recognition Systems</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.15283.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">33</a></td>
                    <td width="800">Modeling speech recognition and synthesis simultaneously: Encoding and decoding lexical and sublexical semantic information into speech with no direct access to speech data</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.11476.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">34</a></td>
                    <td width="800">Neural Predictor for Black-Box Adversarial Attacks on Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.09849.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">35</a></td>
                    <td width="800">Recent improvements of ASR models in the face of adversarial attacks</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16536.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">36</a></td>
                    <td width="800">Sentiment Word Aware Multimodal Refinement for Multimodal Sentiment Analysis with ASR Errors</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.00257.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">37</a></td>
                    <td width="800">Seq-2-Seq based Refinement of ASR Output for Spoken Name Capture</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.15833.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">38</a></td>
                    <td width="800">Spatial Processing Front-End For Distant ASR Exploiting Self-Attention Channel Combinator</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.13919.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">39</a></td>
                    <td width="800">Towards Privacy-Preserving Speech Representation for Client-Side Data Sharing</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.14171.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">40</a></td>
                    <td width="800">Vakyansh: ASR Toolkit for Low Resource Indic languages</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2203.16512.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">41</a></td>
                    <td width="800">Disappeared Command: Spoofing Attack On Automatic Speech Recognition Systems with Sound Masking</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.08977.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">42</a></td>
                    <td width="800">Extracting Targeted Training Data from ASR Models, and How to Mitigate It</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.08345.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">43</a></td>
                    <td width="800">ASR in German: A Detailed Error Analysis</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.05617.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">44</a></td>
                    <td width="800">Unified Speech-Text Pre-training for Speech Translation and Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.05409.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">45</a></td>
                    <td width="800">Building an ASR Error Robust Spoken Virtual Patient System in a Highly Class-Imbalanced Scenario Without Speech Data</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.05183.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">46</a></td>
                    <td width="800">Exploiting Hidden Representations from a DNN-based Speech Recogniser for Speech Intelligibility Prediction in Hearing-impaired Listeners</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.04287.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">47</a></td>
                    <td width="800">Defense against Adversarial Attacks on Hybrid Speech Recognition using Joint Adversarial Fine-tuning with Denoiser</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.03851.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">48</a></td>
                    <td width="800">Personal VAD 2.0: Optimizing Personal Voice Activity Detection for On-Device Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.03793.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">49</a></td>
                    <td width="800">Successes and critical failures of neural networks in capturing human-like speech recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.03740.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">50</a></td>
                    <td width="800">Leveraging Phone Mask Training for Phonetic-Reduction-Robust E2E Uyghur Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.00819.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">51</a></td>
                    <td width="800">End-to-end multi-talker audio-visual ASR using an active speaker attention module</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.00652.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">52</a></td>
                    <td width="800">End-to-End Integration of Speech Recognition, Speech Enhancement, and Self-Supervised Learning Representation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.00540.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">53</a></td>
                    <td width="800">Zero-Shot Cross-lingual Aphasia Detection using Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2204.00448.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">54</a></td>
                    <td width="800">An Investigation on Applying Acoustic Feature Conversion to ASR of Adult and Child Speech</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.12477.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">55</a></td>
                    <td width="800">FLEURS: Few-shot Learning Evaluation of Universal Representations of Speech</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.12446.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">56</a></td>
                    <td width="800">Content-Context Factorized Representations for Automated Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.09872.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">57</a></td>
                    <td width="800">Insights on Neural Representations for End-to-End Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.09456.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">58</a></td>
                    <td width="800">Streaming Noise Context Aware Enhancement For Automatic Speech Recognition in Multi-Talker Environments</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.08555.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">59</a></td>
                    <td width="800">SAMU-XLSR: Semantically-Aligned Multimodal Utterance-level Cross-Lingual Speech Representation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.0818.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">60</a></td>
                    <td width="800">Best of Both Worlds: Multi-task Audio-Visual Automatic Speech Recognition and Active Speaker Detection</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.05206.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">61</a></td>
                    <td width="800">Separator-Transducer-Segmenter: Streaming Recognition and Segmentation of Multi-party Speech</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.05199.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">62</a></td>
                    <td width="800">Hearing voices at the National Library -- a speech corpus and acoustic model for the Swedish language</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2205.03026.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">63</a></td>
                    <td width="800">Challenges and Opportunities in Multi-device Speech Processing</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.15432.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">64</a></td>
                    <td width="800">Conformer Based Elderly Speech Recognition System for Alzheimer's Disease Detection</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.13232.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">65</a></td>
                    <td width="800">Decoupled Federated Learning for ASR with Non-IID Data</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.09102.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">66</a></td>
                    <td width="800">Exploring Capabilities of Monolingual Audio Transformers using Large Datasets in Automatic Speech Recognition of Czech</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.07627.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">67</a></td>
                    <td width="800">FedNST: Federated Noisy Student Training for Automatic Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.02797.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">68</a></td>
                    <td width="800">Sub-8-Bit Quantization Aware Training for 8-Bit Neural Network Accelerator with On-Device Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.15408.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">69</a></td>
                    <td width="800">TEVR: Improving Speech Recognition by Token Entropy Variance Reduction</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.12693.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">70</a></td>
                    <td width="800">The THUEE System Description for the IARPA OpenASR21 Challenge</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.14660.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">71</a></td>
                    <td width="800">Towards Green ASR: Lossless 4-bit Quantization of a Hybrid TDNN System on the 300-hr Switchboard Corpus</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.11643.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">72</a></td>
                    <td width="800">Transformer-based Automatic Speech Recognition of Formal and Colloquial Czech in MALACH Project</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2206.07666.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">73</a></td>
                    <td width="800">Knowledge-driven Subword Grammar Modeling for Automatic Speech Recognition in Tamil and Kannada</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.13333.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">74</a></td>
                    <td width="800">Subword Dictionary Learning and Segmentation Techniques for Automatic Speech Recognition in Tamil and Kannada</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.13331.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">75</a></td>
                    <td width="800">Implementation Of Tiny Machine Learning Models On Arduino 33 BLE For Gesture And Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.12866.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">76</a></td>
                    <td width="800">ASR Error Detection via Audio-Transcript entailment</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.10849.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">77</a></td>
                    <td width="800">Knowledge Transfer and Distillation from Autoregressive to Non-Autoregressive Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.10600.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">78</a></td>
                    <td width="800">Towards Transfer Learning of wav2vec 2.0 for Automatic Lyric Transcription</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.09747.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">79</a></td>
                    <td width="800">ILASR: Privacy-Preserving Incremental Learning for Automatic Speech Recognition at Production Scale</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.09078.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">80</a></td>
                    <td width="800">Reducing Geographic Disparities in Automatic Speech Recognition via Elastic Weight Consolidation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.07850.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">81</a></td>
                    <td width="800">Sotto Voce: Federated Speech Recognition with Differential Privacy Guarantees</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.07816.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">82</a></td>
                    <td width="800">Position Prediction as an Effective Pretraining Strategy</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.07611.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">83</a></td>
                    <td width="800">Efficient spike encoding algorithms for neuromorphic speech recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.07073.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">84</a></td>
                    <td width="800">RSD-GAN: Regularized Sobolev Defense GAN Against Speech-to-Text Adversarial Attacks</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.06858.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">85</a></td>
                    <td width="800">End-to-end speech recognition modeling from de-identified data</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.05469.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">86</a></td>
                    <td width="800">Branchformer: Parallel MLP-Attention Architectures to Capture Local and Global Context for Speech Recognition and Understanding</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.02971.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">87</a></td>
                    <td width="800">Generating gender-ambiguous voices for privacy-preserving speech recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.01052.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">88</a></td>
                    <td width="800">Improving Transformer-based Conversational ASR by Inter-Sentential Attention Mechanism</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.00883.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">89</a></td>
                    <td width="800">Tree-constrained Pointer Generator with Graph Neural Network Encodings for Contextual Speech Recognition</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.00857.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">90</a></td>
                    <td width="800">Swiss German Speech to Text system evaluation</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.00412.pdf">pdf</a></td>
                </tr>
                <tr>
                    <td width="150" align="center">91</a></td>
                    <td width="800">Updating Only Encoders Prevents Catastrophic Forgetting of End-to-End ASR Models</td>
                    <td width="200"><a href="https://arxiv.org/pdf/2207.00216.pdf">pdf</a></td>
                </tr>
            </table>
            <h3> 2021 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Evaluating User Perception of Speech Recognition System Quality with Semantic Distance Metric</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2110.05376.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Speech recognition for air traffic control via feature learning and end-to-end training</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2111.02654.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</td>
                            <td width="800">A study on native American English speech recognition by Indian listeners with varying word familiarity level</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.04151.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</td>
                            <td width="800">Blackbox Untargeted Adversarial Testing of Automatic Speech Recognition Systems</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2112.01821.pdf">pdf</a></td>
                        </tr>
             </table>
        </div>
    </div>
</section>

<!--页脚-->
<footer class="footer">
    <div class="container">
        <div class="rwo">
            <div class="col-md-12">
                <p>
                    本站内容源自互联网，如有内容侵犯了你的权益，请联系删除相关内容，联系邮箱：yongqiangli@alumni.hust.edu.cn
                </p>
                <!--代码源自小呆导航的开源代码，遵循MIT协议，此处保留源代码的声明-->
                <p>
                    Copyright © 2018-2021 li yongqiang All Rights Reserved
                </p>
            </div>
        </div>
    </div>
</footer>
</div>
<!--内容区域-->
</div>
<div id="get-top" title="回到顶部">
    <i class="icon icon-arrow-up"></i>
</div>

<!-- jQuery (ZUI中的Javascript组件依赖于jQuery) -->
<script src="http://code.jquery.com/jquery-1.11.0.min.js"></script>

<script>
    window.onscroll = function(){
//回到顶部
var sllTop = document.documentElement.scrollTop||document.body.scrollTop;
if(sllTop>240){
  $('#get-top').css('display','block')
}else{
  $('#get-top').css('display','none')
}
}
$('#get-top').click(function(){ 
  $('body,html').animate({
    scrollTop: 0
  }, 800);//点击回到顶部按钮，数字越小越快
})
//判断用户使用的设备
var deviceVal  = browserRedirect();
function browserRedirect() {
  var sUserAgent = navigator.userAgent.toLowerCase();
  var bIsIpad = sUserAgent.match(/ipad/i) == "ipad";
  var bIsIphoneOs = sUserAgent.match(/iphone os/i) == "iphone os";
  var bIsMidp = sUserAgent.match(/midp/i) == "midp";
  var bIsUc7 = sUserAgent.match(/rv:1.2.3.4/i) == "rv:1.2.3.4";
  var bIsUc = sUserAgent.match(/ucweb/i) == "ucweb";
  var bIsAndroid = sUserAgent.match(/android/i) == "android";
  var bIsCE = sUserAgent.match(/windows ce/i) == "windows ce";
  var bIsWM = sUserAgent.match(/windows mobile/i) == "windows mobile";
  if (bIsIpad || bIsIphoneOs || bIsMidp || bIsUc7 || bIsUc || bIsAndroid || bIsCE || bIsWM) {
    return 'phone';
} else {
    return 'pc';
}
}
$('.nav-btn').on('click', function () {
    $('.nav').toggleClass('showNav');
    $(this).toggleClass('animated2');
});

</script>
</div>
</body>
</html>
